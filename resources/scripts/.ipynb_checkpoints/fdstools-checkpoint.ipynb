{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222e67c-151b-4ad5-8852-98a705f2587b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d753ada-4402-4411-b20f-44da4deeae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8d318-e797-4743-812e-cd5533ddf445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed278574-11e0-463b-a102-a1576d778a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdbb55-7981-4953-91b1-e8e57744e255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf24e84-4d95-4125-8e6f-7dee9e2ece49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652b9c2d-79d4-4d76-aac1-e26d6439b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 10: Extract numeric positions from the sequence column for sorting\n",
    "def extract_position(seq):\n",
    "    match = re.search(r\"(\\d+\\.?\\d*)\", seq)\n",
    "    return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Define function to process FDSTools SAST TSV files\n",
    "def process_fdstools_sast(file_path: str, threshold: float = 8.0):\n",
    "    IUPAC_CODES = {\n",
    "        frozenset([\"A\", \"G\"]): \"R\",\n",
    "        frozenset([\"C\", \"T\"]): \"Y\",\n",
    "        frozenset([\"A\", \"C\"]): \"M\",\n",
    "        frozenset([\"G\", \"T\"]): \"K\",\n",
    "        frozenset([\"G\", \"C\"]): \"S\",\n",
    "        frozenset([\"A\", \"T\"]): \"W\"\n",
    "    }\n",
    "\n",
    "    # Load the FDSTools SAST TSV file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "    # Convert total_mp_sum and total to numeric types\n",
    "    df[\"total_mp_sum\"] = pd.to_numeric(df[\"total_mp_sum\"], errors=\"coerce\")\n",
    "    df[\"total\"] = pd.to_numeric(df[\"total\"], errors=\"coerce\")\n",
    "\n",
    "    # Count each target (e.g. mtNG_004) and flag those with a single occurrence and low total\n",
    "    marker_counts = df[\"marker\"].value_counts()\n",
    "    single_low_coverage = df[df[\"marker\"].isin(marker_counts[marker_counts == 1].index) & (df[\"total\"] < 10)].copy()\n",
    "\n",
    "    # if not single_low_coverage.empty:\n",
    "    #     print(\"Markers with single entries and total < 10:\")\n",
    "    #     print(single_low_coverage[[\"marker\", \"sequence\", \"total\"]])\n",
    "\n",
    "    # Replace 'sequence' column with 'marker' for low-coverage targets\n",
    "    single_low_coverage[\"sequence\"] = single_low_coverage[\"marker\"]\n",
    "    single_low_coverage = single_low_coverage.drop(columns=[\"marker\"])\n",
    "    \n",
    "    # Optional: Write to CSV for external review\n",
    "    # single_low_coverage.to_csv(\"low_coverage_singleton_segments.csv\", index=False)\n",
    "\n",
    "    \n",
    "    # Step 1: Fill NaN in total and total_mp_sum with zeros\n",
    "    df[\"total\"] = df[\"total\"].fillna(0)\n",
    "    df[\"total_mp_sum\"] = df[\"total_mp_sum\"].fillna(0)\n",
    "\n",
    "    # Step 2: Flag rows with total read depth lower than threshold and low-confidence sequences\n",
    "    df[\"is_noise_or_low\"] = (df[\"sequence\"].isin([\"Other sequences\"])) | (df[\"total_mp_sum\"] < threshold)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "    \"total_mp_max\", \"forward_pct\", \"forward\", \"forward_mp_sum\",\n",
    "    \"forward_mp_max\", \"reverse\", \"reverse_mp_sum\", \"reverse_mp_max\"]\n",
    "    \n",
    "    df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "    # Merge clean_marker_total_wo_OS_THR back into the main DataFrame.\n",
    "    clean_total_per_marker = df[~df[\"is_noise_or_low\"]].groupby(\"marker\")[\"total\"].sum().rename(\"clean_marker_total_wo_OS_THR\")\n",
    "    df = df.merge(clean_total_per_marker, on=\"marker\", how=\"left\")\n",
    "\n",
    "    # Step 3: Compute normalized variant frequency (only for retained rows)\n",
    "    df[\"variant_frequency_wo_OS_THR\"] = (df[\"total\"] / df[\"clean_marker_total_wo_OS_THR\"] * 100).round(2)\n",
    "\n",
    "    # Step 5: Split multiple variants\n",
    "    df = df.assign(sequence=df[\"sequence\"].str.split())\n",
    "    df = df.explode(\"sequence\").reset_index(drop=True)\n",
    "    \n",
    "    # Step 4: Flag rows to drop\n",
    "    drop_seqs = [\"Other\", \"sequences\", \"REF\", \"N3107DEL\"]\n",
    "    df = df[(~df[\"sequence\"].isin(drop_seqs)) & (df[\"total_mp_sum\"] >= threshold)].copy()\n",
    "\n",
    "    # Step 6: Calculate estimated coverage for each row\n",
    "    df[\"estimated_total_coverage\"] = (\n",
    "        df[\"total\"] / (df[\"total_mp_sum\"] / 100)\n",
    "    ).round(0).astype(\"Int64\")\n",
    "\n",
    "    # Step 7: Group by marker + sequence to sum within same marker\n",
    "    grouped_same_marker = df.groupby([\"marker\", \"sequence\"], as_index=False).agg(\n",
    "        # total=(\"total\", \"sum\"),\n",
    "        # total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        # estimated_total_coverage=(\"estimated_total_coverage\", \"sum\")\n",
    "        total=(\"total\", \"sum\"),\n",
    "        total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        estimated_total_coverage=(\"estimated_total_coverage\", \"max\"),\n",
    "        is_noise_or_low=(\"is_noise_or_low\", \"first\"),\n",
    "        clean_marker_total_wo_OS_THR=(\"clean_marker_total_wo_OS_THR\", \"first\"),\n",
    "        variant_frequency_wo_OS_THR=(\"variant_frequency_wo_OS_THR\", \"sum\")\n",
    "    )\n",
    "    # # print(grouped_same_marker)\n",
    "    # # Step 8: Recompute variant_frequency within marker\n",
    "    # grouped_same_marker[\"variant_frequency\"] = (\n",
    "    #     grouped_same_marker[\"total\"] / grouped_same_marker[\"estimated_total_coverage\"] * 100\n",
    "    # ).round(1)\n",
    "\n",
    "    # print(grouped_same_marker)\n",
    "    \n",
    "    # Step 9: Group across markers to merge overlapping amplicons (same variant)\n",
    "    # df[\"estimated_total_coverage_across_markers\"] = (df[\"total\"] / (df[\"total_mp_sum\"] / 100)).round(0).astype(\"Int64\")\n",
    "    grouped_final = grouped_same_marker.groupby(\"sequence\", as_index=False).agg(\n",
    "        total=(\"total\", \"sum\"),\n",
    "        # total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        estimated_total_coverage=(\"estimated_total_coverage\", \"sum\"),\n",
    "        # estimated_total_coverage_across_markers=(\"estimated_total_coverage_across_markers\", \"sum\"),\n",
    "        is_noise_or_low=(\"is_noise_or_low\", \"first\"),\n",
    "        clean_marker_total_wo_OS_THR=(\"clean_marker_total_wo_OS_THR\", \"sum\"),\n",
    "        # variant_frequency_wo_OS_THR=(\"variant_frequency_wo_OS_THR\", \"sum\"),\n",
    "        num_markers=(\"marker\", \"nunique\")\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # print(grouped_final)\n",
    "    \n",
    "    grouped_final[\"variant_frequency\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"estimated_total_coverage\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    grouped_final[\"variant_frequency_wo_OS_THR\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"clean_marker_total_wo_OS_THR\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"sequence\"].apply(extract_position)\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    \n",
    "    # Step 11: Apply IUPAC codes for heteroplasmies\n",
    "    # Step 11: Apply IUPAC codes and adjust formatting for heteroplasmies\n",
    "    def resolve_heteroplasmy(row):\n",
    "        seq = row['sequence']\n",
    "    \n",
    "        # Handle deletions\n",
    "        if 'DEL' in seq:\n",
    "            return seq.replace('DEL', '-')\n",
    "\n",
    "        # Handle insertions: prefix with \"-\"\n",
    "\n",
    "        # Handle insertions / length heteroplasmies\n",
    "        if '.' in seq:\n",
    "            if row['variant_frequency_wo_OS_THR'] < 92:\n",
    "                return '-' + seq[:-1] + seq[-1].lower()  # e.g. 309.2C -> 309.2c\n",
    "            else:\n",
    "                return '-' + seq # leave as-is if frequency is high\n",
    "\n",
    "        # Handle point heteroplasmies with IUPAC\n",
    "        if row['variant_frequency_wo_OS_THR'] < 92:\n",
    "            match = re.match(r'([ACGT])(\\d+)([ACGT])', seq)\n",
    "            if not match:\n",
    "                return seq\n",
    "            ref, pos, alt = match.groups()\n",
    "            code = IUPAC_CODES.get(frozenset([ref, alt]))\n",
    "            if code:\n",
    "                return f\"{ref}{pos}{code}\"\n",
    "    \n",
    "        return seq\n",
    "\n",
    "\n",
    "\n",
    "    grouped_final['sequence'] = grouped_final.apply(resolve_heteroplasmy, axis=1)\n",
    "\n",
    "    grouped_final = pd.concat([grouped_final, single_low_coverage], ignore_index=False)\n",
    "\n",
    "    print(grouped_final)\n",
    "    \n",
    "    return grouped_final\n",
    "    # return grouped_final, df\n",
    "\n",
    "# # Placeholder path \n",
    "tsv_path = \"s23-11298-E1_S16_L001.sast.csv\"\n",
    "reference_sequence = \"../rCRS/rCRS2.fasta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bdc3b07-c7c6-4d39-8fd8-99f497e091c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markers with single entries and total < 10:\n",
      "       marker sequence  total\n",
      "499  mtNG_099  No data      0\n",
      "      sequence  total  estimated_total_coverage is_noise_or_low  \\\n",
      "7        A263G   1853                      2037           False   \n",
      "1      -309.1C    469                       588           False   \n",
      "2      -309.2c    114                       588           False   \n",
      "3      -315.1C    469                       588           False   \n",
      "11       A523-   1478                      1802           False   \n",
      "16       C524-   1478                      1802           False   \n",
      "13       A750G   2298                      2479           False   \n",
      "4       A1438G   1887                      2026           False   \n",
      "18      G3010A   2049                      2173           False   \n",
      "8       A3447M     28                       172           False   \n",
      "9       A3796G   3294                      3504           False   \n",
      "10      A4769G    927                       998           False   \n",
      "12      A6419M    192                      2015           False   \n",
      "14      A8860G   1472                      1643           False   \n",
      "5      A15326G   1917                      2137           False   \n",
      "17     G16129A    230                       291           False   \n",
      "6      A16183C    230                       291           False   \n",
      "19     T16189Y    198                       290           False   \n",
      "20     T16189-     32                       291           False   \n",
      "0    -16193.1c     95                       290           False   \n",
      "15     C16355T    639                       686           False   \n",
      "21     T16356C    639                       686           False   \n",
      "22     T16362C    639                       686           False   \n",
      "23     T16519C   1738                      1824           False   \n",
      "499   mtNG_099      0                      <NA>             NaN   \n",
      "\n",
      "     clean_marker_total_wo_OS_THR  num_markers  variant_frequency  \\\n",
      "7                          1853.0          2.0               91.0   \n",
      "1                           469.0          1.0               79.8   \n",
      "2                           469.0          1.0               19.4   \n",
      "3                           469.0          1.0               79.8   \n",
      "11                         1478.0          1.0               82.0   \n",
      "16                         1478.0          1.0               82.0   \n",
      "13                         2298.0          1.0               92.7   \n",
      "4                          1887.0          2.0               93.1   \n",
      "18                         2049.0          1.0               94.3   \n",
      "8                            49.0          1.0               16.3   \n",
      "9                          3294.0          1.0               94.0   \n",
      "10                          927.0          1.0               92.9   \n",
      "12                         1850.0          1.0                9.5   \n",
      "14                         1472.0          1.0               89.6   \n",
      "5                          1917.0          1.0               89.7   \n",
      "17                          230.0          1.0               79.0   \n",
      "6                           230.0          1.0               79.0   \n",
      "19                          230.0          1.0               68.3   \n",
      "20                          230.0          1.0               11.0   \n",
      "0                           230.0          1.0               32.8   \n",
      "15                          639.0          1.0               93.1   \n",
      "21                          639.0          1.0               93.1   \n",
      "22                          639.0          1.0               93.1   \n",
      "23                         1738.0          1.0               95.3   \n",
      "499                           NaN          NaN               <NA>   \n",
      "\n",
      "     variant_frequency_wo_OS_THR flags  total_mp_sum total_mp_max forward_pct  \\\n",
      "7                          100.0   NaN           NaN          NaN         NaN   \n",
      "1                          100.0   NaN           NaN          NaN         NaN   \n",
      "2                           24.3   NaN           NaN          NaN         NaN   \n",
      "3                          100.0   NaN           NaN          NaN         NaN   \n",
      "11                         100.0   NaN           NaN          NaN         NaN   \n",
      "16                         100.0   NaN           NaN          NaN         NaN   \n",
      "13                         100.0   NaN           NaN          NaN         NaN   \n",
      "4                          100.0   NaN           NaN          NaN         NaN   \n",
      "18                         100.0   NaN           NaN          NaN         NaN   \n",
      "8                           57.1   NaN           NaN          NaN         NaN   \n",
      "9                          100.0   NaN           NaN          NaN         NaN   \n",
      "10                         100.0   NaN           NaN          NaN         NaN   \n",
      "12                          10.4   NaN           NaN          NaN         NaN   \n",
      "14                         100.0   NaN           NaN          NaN         NaN   \n",
      "5                          100.0   NaN           NaN          NaN         NaN   \n",
      "17                         100.0   NaN           NaN          NaN         NaN   \n",
      "6                          100.0   NaN           NaN          NaN         NaN   \n",
      "19                          86.1   NaN           NaN          NaN         NaN   \n",
      "20                          13.9   NaN           NaN          NaN         NaN   \n",
      "0                           41.3   NaN           NaN          NaN         NaN   \n",
      "15                         100.0   NaN           NaN          NaN         NaN   \n",
      "21                         100.0   NaN           NaN          NaN         NaN   \n",
      "22                         100.0   NaN           NaN          NaN         NaN   \n",
      "23                         100.0   NaN           NaN          NaN         NaN   \n",
      "499                          NaN   NaN           0.0         0.00        0.00   \n",
      "\n",
      "    forward forward_mp_sum forward_mp_max reverse reverse_mp_sum  \\\n",
      "7       NaN            NaN            NaN     NaN            NaN   \n",
      "1       NaN            NaN            NaN     NaN            NaN   \n",
      "2       NaN            NaN            NaN     NaN            NaN   \n",
      "3       NaN            NaN            NaN     NaN            NaN   \n",
      "11      NaN            NaN            NaN     NaN            NaN   \n",
      "16      NaN            NaN            NaN     NaN            NaN   \n",
      "13      NaN            NaN            NaN     NaN            NaN   \n",
      "4       NaN            NaN            NaN     NaN            NaN   \n",
      "18      NaN            NaN            NaN     NaN            NaN   \n",
      "8       NaN            NaN            NaN     NaN            NaN   \n",
      "9       NaN            NaN            NaN     NaN            NaN   \n",
      "10      NaN            NaN            NaN     NaN            NaN   \n",
      "12      NaN            NaN            NaN     NaN            NaN   \n",
      "14      NaN            NaN            NaN     NaN            NaN   \n",
      "5       NaN            NaN            NaN     NaN            NaN   \n",
      "17      NaN            NaN            NaN     NaN            NaN   \n",
      "6       NaN            NaN            NaN     NaN            NaN   \n",
      "19      NaN            NaN            NaN     NaN            NaN   \n",
      "20      NaN            NaN            NaN     NaN            NaN   \n",
      "0       NaN            NaN            NaN     NaN            NaN   \n",
      "15      NaN            NaN            NaN     NaN            NaN   \n",
      "21      NaN            NaN            NaN     NaN            NaN   \n",
      "22      NaN            NaN            NaN     NaN            NaN   \n",
      "23      NaN            NaN            NaN     NaN            NaN   \n",
      "499       0           0.00           0.00       0           0.00   \n",
      "\n",
      "    reverse_mp_max  \n",
      "7              NaN  \n",
      "1              NaN  \n",
      "2              NaN  \n",
      "3              NaN  \n",
      "11             NaN  \n",
      "16             NaN  \n",
      "13             NaN  \n",
      "4              NaN  \n",
      "18             NaN  \n",
      "8              NaN  \n",
      "9              NaN  \n",
      "10             NaN  \n",
      "12             NaN  \n",
      "14             NaN  \n",
      "5              NaN  \n",
      "17             NaN  \n",
      "6              NaN  \n",
      "19             NaN  \n",
      "20             NaN  \n",
      "0              NaN  \n",
      "15             NaN  \n",
      "21             NaN  \n",
      "22             NaN  \n",
      "23             NaN  \n",
      "499           0.00  \n"
     ]
    }
   ],
   "source": [
    "processed_df = process_fdstools_sast(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8182ec-9d6b-4f0d-b830-4fe3593c2cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "26acfdb6-5ab7-4b40-8705-0805a718664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"s23-11303-E1_S13_L001_processed10.txt\" \n",
    "processed_df.to_csv(output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2980e6-7cf1-4f9c-bf97-d0aa67debcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5888a8a7-917d-4624-9c79-df85c494882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def process_empop_variant_table(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a variant table with EMPOP-style variant annotations.\n",
    "    - Splits multi-variant rows\n",
    "    - Sums VariantLevel and allele-specific Coverage\n",
    "    - Keeps the first value of MeanBaseQuality\n",
    "    - Sorts variants by position\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: path to the tab-separated file\n",
    "\n",
    "    Returns:\n",
    "    - A cleaned and sorted DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Load file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    # Split EMPOP_Variant column and explode into rows\n",
    "    df[\"EMPOP_Variant\"] = df[\"EMPOP_Variant\"].astype(str).str.split()\n",
    "    df = df.explode(\"EMPOP_Variant\").reset_index(drop=True)\n",
    "\n",
    "    # Convert numeric columns\n",
    "    df[\"VariantLevel\"] = pd.to_numeric(df[\"VariantLevel\"], errors=\"coerce\")\n",
    "\n",
    "    # Helper: sum comma-separated numbers elementwise\n",
    "    def add_comma_separated_numbers(series):\n",
    "        split_lists = series.dropna().astype(str).apply(lambda x: list(map(float, x.split(','))))\n",
    "        if split_lists.empty:\n",
    "            return \"\"\n",
    "        summed = [sum(x) for x in zip(*split_lists)]\n",
    "        return \",\".join(f\"{s:.4g}\" for s in summed)\n",
    "\n",
    "    # Aggregate\n",
    "    group_keys = [\"EMPOP_Variant\"]\n",
    "    numeric_agg = {\n",
    "        \"VariantLevel\": \"sum\",\n",
    "        \"Coverage\": add_comma_separated_numbers,\n",
    "        \"MeanBaseQuality\": \"first\"\n",
    "    }\n",
    "    other_cols = [col for col in df.columns if col not in numeric_agg and col not in group_keys]\n",
    "    full_agg = {**numeric_agg, **{col: \"first\" for col in other_cols}}\n",
    "\n",
    "    grouped = df.groupby(group_keys, as_index=False).agg(full_agg)\n",
    "\n",
    "    # Sort by numeric position extracted from variant\n",
    "    def extract_position(variant):\n",
    "        match = re.search(r\"(\\d+\\.?\\d*)\", str(variant))\n",
    "        return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "    grouped[\"position\"] = grouped[\"EMPOP_Variant\"].apply(extract_position)\n",
    "    grouped = grouped.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    def correct_length_het_case(row):\n",
    "        if \".\" in row[\"EMPOP_Variant\"] and row[\"VariantLevel\"] >= 0.92:\n",
    "            return row[\"EMPOP_Variant\"][:-1] + row[\"EMPOP_Variant\"][-1].upper()\n",
    "        return row[\"EMPOP_Variant\"]\n",
    "\n",
    "    grouped[\"EMPOP_Variant\"] = grouped.apply(correct_length_het_case, axis=1)\n",
    "    \n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ceafbc3a-056a-4ff3-9630-2023599d465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop.txt\"\n",
    "grouped_variants = process_empop_variant_table(input_path)\n",
    "\n",
    "# Save results\n",
    "grouped_variants.to_csv(\"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop_grouped.txt\", sep=\"\\t\", index=False)\n",
    "# exploded_df.to_csv(\"exploded_variants.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ead507-3231-44e9-9958-d9b5ea95c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned = process_empop_variant_table(\"your_input_file.tsv\")\n",
    "# df_cleaned.to_csv(\"cleaned_empop_variants.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0e857020-4262-408c-a6c4-38158868ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def merge_variant_callers(file1: str, file2: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges two variant tables from different callers on their variant column.\n",
    "    \n",
    "    Parameters:\n",
    "        file1: Path to the first variant caller table (expects 'sequence' column)\n",
    "        file2: Path to the second variant caller table (expects 'EMPOP_Variant' column)\n",
    "        \n",
    "    Returns:\n",
    "        A merged DataFrame with flags and full column preservation, sorted by position.\n",
    "    \"\"\"\n",
    "    # Load both files\n",
    "    df1 = pd.read_csv(file1, sep=\"\\t\")\n",
    "    df2 = pd.read_csv(file2, sep=\"\\t\")\n",
    "    \n",
    "    # Rename variant columns to common key\n",
    "    df1 = df1.rename(columns={\"sequence\": \"variant\"})\n",
    "    df2 = df2.rename(columns={\"EMPOP_Variant\": \"variant\"})\n",
    "    \n",
    "    # Merge the dataframes on the variant column\n",
    "    merged = pd.merge(df1, df2, on=\"variant\", how=\"outer\", suffixes=(\"_vc1\", \"_vc2\"))\n",
    "\n",
    "    # Add flags for presence in each caller\n",
    "    merged[\"called_in_vc1\"] = ~merged[\"total\"].isna()\n",
    "    merged[\"called_in_vc2\"] = ~merged[\"VariantLevel\"].isna()\n",
    "\n",
    "    # Extract numeric position for sorting\n",
    "    def extract_position(seq):\n",
    "        match = re.search(r\"(\\d+\\.?\\d*)\", str(seq))\n",
    "        return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "    merged[\"variant_position\"] = merged[\"variant\"].apply(extract_position)\n",
    "    merged = merged.sort_values(by=\"variant_position\").drop(columns=[\"variant_position\"])\n",
    "\n",
    "    # Reorder columns for clarity\n",
    "    front = [\"variant\", \"called_in_vc1\", \"called_in_vc2\"]\n",
    "    other = [col for col in merged.columns if col not in front]\n",
    "    merged = merged[front + other]\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4acd3a2d-f8c8-498c-9ad8-7742f5e4dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_variant_callers(\"s23-11303-E1_S13_L001_processed10.txt\",\"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop_grouped.txt\")\n",
    "df_merged.to_csv(\"merged_variants2.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "84e5529b-129d-4f2e-9171-66cd7ddd067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Step 10: Extract numeric positions from the sequence column for sorting\n",
    "def extract_position(seq):\n",
    "    match = re.search(r\"(\\d+\\.?\\d*)\", seq)\n",
    "    return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Step 11: Apply IUPAC codes and adjust formatting for heteroplasmies\n",
    "def resolve_heteroplasmy(row, min_variant_frequency_pct, length_heteroplasmy_threshold, IUPAC_CODES):\n",
    "    seq = row['sequence']\n",
    "\n",
    "    # Handle deletions\n",
    "    if 'DEL' in seq:\n",
    "        return seq.replace('DEL', '-')\n",
    "\n",
    "    # Handle insertions / length heteroplasmies\n",
    "    if '.' in seq:\n",
    "        if row['variant_frequency'] < length_heteroplasmy_threshold:\n",
    "            return '-' + seq[:-1] + seq[-1].lower()  # e.g. 309.2C -> 309.2c\n",
    "        else:\n",
    "            return '-' + seq # leave as-is if frequency is high\n",
    "\n",
    "    # Handle point heteroplasmies with IUPAC\n",
    "    if row['variant_frequency'] < 100-min_variant_frequency_pct:\n",
    "        match = re.match(r'([ACGT])(\\d+)([ACGT])', seq)\n",
    "        if not match:\n",
    "            return seq\n",
    "        ref, pos, alt = match.groups()\n",
    "        code = IUPAC_CODES.get(frozenset([ref, alt]))\n",
    "        if code:\n",
    "            return f\"{ref}{pos}{code}\"\n",
    "\n",
    "    return seq\n",
    "\n",
    "def load_marker_ranges(filepath):\n",
    "    marker_ranges = {}\n",
    "    in_position_block = False\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"[genome_position]\"):\n",
    "                in_position_block = True\n",
    "                continue\n",
    "            if line.startswith(\"[\") and in_position_block:\n",
    "                # Stop if another block begins\n",
    "                break\n",
    "            if in_position_block and \"=\" in line:\n",
    "                marker, values = line.split(\"=\")\n",
    "                marker = marker.strip()\n",
    "                parts = [v.strip() for v in values.split(\",\")]\n",
    "                if len(parts) >= 3:\n",
    "                    chrom, start, end = parts[:3]\n",
    "                    marker_ranges[marker] = f\"{chrom}:{start}â€“{end}\"\n",
    "    return marker_ranges\n",
    "\n",
    "# Define function to process FDSTools SAST TSV files\n",
    "def process_fdstools_sast(file_path: str, min_variant_frequency_pct: float = 5.0, depth_threshold: int = 10, length_heteroplasmy_threshold: float = 90.0):\n",
    "    IUPAC_CODES = {\n",
    "        frozenset([\"A\", \"G\"]): \"R\",\n",
    "        frozenset([\"C\", \"T\"]): \"Y\",\n",
    "        frozenset([\"A\", \"C\"]): \"M\",\n",
    "        frozenset([\"G\", \"T\"]): \"K\",\n",
    "        frozenset([\"G\", \"C\"]): \"S\",\n",
    "        frozenset([\"A\", \"T\"]): \"W\"\n",
    "    }\n",
    "\n",
    "    # Load the FDSTools SAST TSV file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "    \"total_mp_max\", \"forward_pct\", \"forward\", \"forward_mp_sum\",\n",
    "    \"forward_mp_max\", \"reverse\", \"reverse_mp_sum\", \"reverse_mp_max\"]\n",
    "    \n",
    "    df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "    \n",
    "    # # Convert total_mp_sum and total to numeric types\n",
    "    df[\"total_mp_sum\"] = pd.to_numeric(df[\"total_mp_sum\"], errors=\"coerce\")\n",
    "    df[\"total\"] = pd.to_numeric(df[\"total\"], errors=\"coerce\")\n",
    "\n",
    "    # Count each marker (e.g. mtNG_001 or mtNG_007) and flag those with a single occurrence and low total\n",
    "    marker_counts = df[\"marker\"].value_counts()\n",
    "    # print(marker_counts)\n",
    "    single_low_coverage = df[df[\"marker\"].isin(marker_counts[marker_counts == 1].index) & (df[\"total\"] < depth_threshold)].copy()\n",
    "    print(single_low_coverage)\n",
    "    \n",
    "    # Step 1: Fill NaN in total and total_mp_sum with zeros\n",
    "    df[\"total\"] = df[\"total\"].fillna(0)\n",
    "    df[\"total_mp_sum\"] = df[\"total_mp_sum\"].fillna(0)\n",
    "\n",
    "    # df = df[df[\"marker\"] == \"mtNG_005\"]    \n",
    "    df = df[df[\"marker\"].isin([\"mtNG_001\", \"mtNG_002\"])]\n",
    "    # Step 2: Flag rows with total read depth lower than threshold and low-confidence sequences\n",
    "    # df[\"is_noise_or_low_frq\"] = (df[\"sequence\"].isin([\"Other sequences\"])) & (df[\"total_mp_sum\"] < 0)\n",
    " \n",
    "\n",
    "    # Step 5: Split multiple variants\n",
    "    df = df.assign(sequence=df[\"sequence\"].str.split())\n",
    "    df = df.explode(\"sequence\").reset_index(drop=True)\n",
    "    # print(df)\n",
    "    \n",
    "    # Merge clean_marker_total_wo_OS_THR back into the main DataFrame.\n",
    "    # clean_total_per_marker = df[~df[\"is_noise_or_low_frq\"]].groupby(\"marker\")[\"total\"].sum().rename(\"total_wo_noise_or_low_frq\")\n",
    "    # print(clean_total_per_marker)\n",
    "    # df = df.merge(clean_total_per_marker, on=\"marker\", how=\"left\")    \n",
    "\n",
    "    # Step 3: Compute normalized variant frequency (only for retained rows)\n",
    "    # df[\"variant_frequency_wo_noise_or_low_frq\"] = (df[\"total\"] / df[\"total_wo_noise_or_low_frq\"] * 100).round(2)\n",
    "    # print(df)\n",
    "\n",
    "\n",
    "    # # Step 4: Flag rows to drop LETS THINK ABOUT THIS, WHEN IS THE BEST TIME TO FILTER THESE OUT?\n",
    "    # drop_seqs = [\"Other\", \"sequences\", \"REF\", \"N3107DEL\"]\n",
    "    # df = df[(~df[\"sequence\"].isin(drop_seqs)) & (df[\"total_mp_sum\"] >= min_variant_frequency_pct)].copy()\n",
    "\n",
    "    \n",
    "    df[\"interpolated_total_coverage\"] = (np.ceil(df[\"total\"] / (df[\"total_mp_sum\"] / 100))).astype(\"Int64\")\n",
    "\n",
    "    # Step 7: Group by marker + sequence to sum within same marker\n",
    "    grouped_same_marker = df.groupby([\"marker\", \"sequence\"], as_index=False).agg(\n",
    "        total=(\"total\", \"sum\"),\n",
    "        total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        interpolated_total_coverage=(\"interpolated_total_coverage\", \"max\"),\n",
    "        # is_noise_or_low_frq=(\"is_noise_or_low_frq\", \"first\"),\n",
    "        # total_wo_noise_or_low_frq=(\"total_wo_noise_or_low_frq\", \"first\"),\n",
    "        # variant_frequency_wo_noise_or_low_frq=(\"variant_frequency_wo_noise_or_low_frq\", \"sum\")\n",
    "    )\n",
    "    # print(grouped_same_marker)\n",
    "\n",
    "    # # Step 9: Group across markers to merge overlapping amplicons (same variant)\n",
    "    grouped_final = grouped_same_marker.groupby(\"sequence\", as_index=False).agg(\n",
    "        marker=(\"marker\", \"first\"),\n",
    "        total=(\"total\", \"sum\"),\n",
    "        interpolated_total_coverage=(\"interpolated_total_coverage\", \"sum\"),\n",
    "        # is_noise_or_low_frq=(\"is_noise_or_low_frq\", \"first\"),\n",
    "        # total_wo_noise_or_low_frq=(\"total_wo_noise_or_low_frq\", \"sum\"),\n",
    "        num_markers=(\"marker\", \"nunique\")\n",
    "    )\n",
    "    # print(grouped_same_marker)\n",
    "    \n",
    "    \n",
    "    grouped_final[\"variant_frequency\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"interpolated_total_coverage\"] * 100\n",
    "    ).round(2)\n",
    "\n",
    "    # grouped_final[\"variant_frequency_wo_noise_or_low_frq\"] = (\n",
    "    #     grouped_final[\"total\"] / grouped_final[\"total_wo_noise_or_low_frq\"] * 100\n",
    "    # ).round(2)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"sequence\"].apply(extract_position)\n",
    "    # grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "    \n",
    "    grouped_final[\"is_noise_or_low_frq\"] = (grouped_final[\"sequence\"].isin([\"Other sequences\"])) | (grouped_final[\"variant_frequency\"] < 1)\n",
    "    grouped_final = grouped_final[~grouped_final[\"is_noise_or_low_frq\"]]\n",
    "    print(grouped_final)\n",
    "    # print(grouped_final)\n",
    "    # Temporary store for merged entries\n",
    "    merged_rows = []\n",
    "    used_indices = set()\n",
    "\n",
    "    for pos, group in grouped_final.groupby(\"position\"):\n",
    "        if group.shape[0] != 2:\n",
    "            continue\n",
    "\n",
    "        # Identify deletion and substitution\n",
    "        del_row = group[group[\"sequence\"].str.endswith(\"DEL\")]\n",
    "        # print(del_row)\n",
    "        sub_row = group[~group[\"sequence\"].str.endswith(\"DEL\")]\n",
    "        # print(sub_row)\n",
    "        \n",
    "        if del_row.empty or sub_row.empty:\n",
    "            continue\n",
    "    \n",
    "        del_idx = del_row.index[0]\n",
    "        # print(del_idx)\n",
    "        sub_idx = sub_row.index[0]\n",
    "    \n",
    "        # Skip if already merged\n",
    "        if del_idx in used_indices or sub_idx in used_indices:\n",
    "            continue\n",
    "    \n",
    "        # Merge logic\n",
    "        # if del_row[\"total\"].iloc[0] >= sub_row[\"total\"].iloc[0]:\n",
    "        #     dominant_row = del_row.iloc[0]\n",
    "        # else:\n",
    "        #     dominant_row = sub_row.iloc[0]\n",
    "        total = del_row[\"total\"].iloc[0] + sub_row[\"total\"].iloc[0]\n",
    "        coverage = del_row[\"total_wo_noise_or_low_frq\"].iloc[0] \n",
    "        freq = round(total / coverage * 100, 1) if coverage else 0\n",
    "        \n",
    "        sub_seq = sub_row[\"sequence\"].iloc[0]\n",
    "        ref, pos_str, alt = re.match(r'([ACGT])(\\d+)([ACGT])', sub_seq).groups()\n",
    "    \n",
    "        # If deletion is the minor variant, return lowercase\n",
    "        # del_freq = del_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "        merged_seq = f\"{ref}{pos_str}{alt.lower()}\" if del_freq < (length_heteroplasmy_threshold) else f\"{ref}{pos_str}{alt}\"\n",
    "\n",
    "        sub_freq = sub_row[\"variant_frequency\"].iloc[0]\n",
    "        # sub_clean_freq = sub_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "        del_freq = del_row[\"variant_frequency\"].iloc[0]\n",
    "        # del_clean_freq = del_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "    \n",
    "        freq_annotation = (\n",
    "            f\"sub:{sub_freq} ({sub_clean_freq}) | \"\n",
    "            f\"del:{del_freq} ({del_clean_freq})\"\n",
    "        )\n",
    "        merged_rows.append({\n",
    "            \"sequence\": merged_seq,\n",
    "            \"total\": total,\n",
    "            \"interpolated_total_coverage\": del_row[\"interpolated_total_coverage\"].iloc[0],\n",
    "            \"is_noise_or_low_frq\": False,\n",
    "            \"total_wo_noise_or_low_frq\": total,  # fallback\n",
    "            \"num_markers\": f\"sub:{sub_row['num_markers'].iloc[0]} | del:{del_row['num_markers'].iloc[0]}\", \n",
    "            \"variant_frequency\": freq_annotation, \n",
    "            \"variant_frequency_wo_noise_or_low_frq\": freq,\n",
    "            \"marker\": sub_row[\"marker\"].iloc[0],  # arbitrary\n",
    "            \"position\": float(pos)\n",
    "        })\n",
    "    \n",
    "        used_indices.update([del_idx, sub_idx])\n",
    "\n",
    "    # Drop merged ones and add new merged row\n",
    "    grouped_final = grouped_final.drop(index=used_indices)\n",
    "    if merged_rows:\n",
    "        grouped_final = pd.concat([grouped_final, pd.DataFrame(merged_rows)], ignore_index=True)\n",
    "\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    grouped_final[\"sequence\"] = grouped_final.apply(\n",
    "        lambda row: resolve_heteroplasmy(\n",
    "            row,\n",
    "            min_variant_frequency_pct,\n",
    "            length_heteroplasmy_threshold,\n",
    "            IUPAC_CODES\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    grouped_final = pd.concat([grouped_final, single_low_coverage], ignore_index=False)\n",
    "\n",
    "    # Load the mapping from your txt file\n",
    "    marker_to_range = load_marker_ranges(\"mtNG_lib2_v211-flank.txt\")\n",
    "    grouped_final[\"marker_range\"] = grouped_final[\"marker\"].map(marker_to_range)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"marker\"].apply(extract_position)\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    return grouped_final\n",
    "\n",
    "tsv_path = \"2800M_L001.sast.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "02f41175-d116-4974-84ae-64500657e78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [marker, sequence, flags, total, total_mp_sum]\n",
      "Index: []\n",
      "   sequence    marker  total  interpolated_total_coverage  num_markers  \\\n",
      "7     A263G  mtNG_002   1438                         1439            1   \n",
      "53    T152C  mtNG_001   1956                         1958            2   \n",
      "\n",
      "    variant_frequency  position  is_noise_or_low_frq  \n",
      "7               99.93     263.0                False  \n",
      "53               99.9     152.0                False  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'variant_frequency_wo_noise_or_low_frq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'variant_frequency_wo_noise_or_low_frq'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m process_fdstools_sast(tsv_path)\n",
      "Cell \u001b[0;32mIn[105], line 231\u001b[0m, in \u001b[0;36mprocess_fdstools_sast\u001b[0;34m(file_path, min_variant_frequency_pct, depth_threshold, length_heteroplasmy_threshold)\u001b[0m\n\u001b[1;32m    227\u001b[0m     grouped_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([grouped_final, pd\u001b[38;5;241m.\u001b[39mDataFrame(merged_rows)], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    229\u001b[0m grouped_final \u001b[38;5;241m=\u001b[39m grouped_final\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 231\u001b[0m grouped_final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m grouped_final\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: resolve_heteroplasmy(\n\u001b[1;32m    233\u001b[0m         row,\n\u001b[1;32m    234\u001b[0m         min_variant_frequency_pct,\n\u001b[1;32m    235\u001b[0m         length_heteroplasmy_threshold,\n\u001b[1;32m    236\u001b[0m         IUPAC_CODES\n\u001b[1;32m    237\u001b[0m     ),\n\u001b[1;32m    238\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    241\u001b[0m grouped_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([grouped_final, single_low_coverage], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Load the mapping from your txt file\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[105], line 232\u001b[0m, in \u001b[0;36mprocess_fdstools_sast.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    227\u001b[0m     grouped_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([grouped_final, pd\u001b[38;5;241m.\u001b[39mDataFrame(merged_rows)], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    229\u001b[0m grouped_final \u001b[38;5;241m=\u001b[39m grouped_final\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    231\u001b[0m grouped_final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m grouped_final\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: resolve_heteroplasmy(\n\u001b[1;32m    233\u001b[0m         row,\n\u001b[1;32m    234\u001b[0m         min_variant_frequency_pct,\n\u001b[1;32m    235\u001b[0m         length_heteroplasmy_threshold,\n\u001b[1;32m    236\u001b[0m         IUPAC_CODES\n\u001b[1;32m    237\u001b[0m     ),\n\u001b[1;32m    238\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    241\u001b[0m grouped_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([grouped_final, single_low_coverage], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Load the mapping from your txt file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[105], line 26\u001b[0m, in \u001b[0;36mresolve_heteroplasmy\u001b[0;34m(row, min_variant_frequency_pct, length_heteroplasmy_threshold, IUPAC_CODES)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m seq \u001b[38;5;66;03m# leave as-is if frequency is high\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Handle point heteroplasmies with IUPAC\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariant_frequency_wo_noise_or_low_frq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m-\u001b[39mmin_variant_frequency_pct:\n\u001b[1;32m     27\u001b[0m     match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([ACGT])(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)([ACGT])\u001b[39m\u001b[38;5;124m'\u001b[39m, seq)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'variant_frequency_wo_noise_or_low_frq'"
     ]
    }
   ],
   "source": [
    "processed_df = process_fdstools_sast(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5320130-1b8c-46e0-8a57-d151a566aad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>marker</th>\n",
       "      <th>total</th>\n",
       "      <th>interpolated_total_coverage</th>\n",
       "      <th>is_noise_or_low_frq</th>\n",
       "      <th>total_wo_noise_or_low_frq</th>\n",
       "      <th>num_markers</th>\n",
       "      <th>variant_frequency</th>\n",
       "      <th>variant_frequency_wo_noise_or_low_frq</th>\n",
       "      <th>flags</th>\n",
       "      <th>total_mp_sum</th>\n",
       "      <th>marker_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>T152Y</td>\n",
       "      <td>mtNG_001</td>\n",
       "      <td>1956</td>\n",
       "      <td>1958</td>\n",
       "      <td>False</td>\n",
       "      <td>3465.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>56.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:19â€“155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>A263R</td>\n",
       "      <td>mtNG_002</td>\n",
       "      <td>2663</td>\n",
       "      <td>2666</td>\n",
       "      <td>False</td>\n",
       "      <td>5489.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.89</td>\n",
       "      <td>48.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:134â€“266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-315.1c</td>\n",
       "      <td>mtNG_003</td>\n",
       "      <td>1216</td>\n",
       "      <td>1227</td>\n",
       "      <td>False</td>\n",
       "      <td>2573.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>47.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:260â€“368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>REF</td>\n",
       "      <td>mtNG_004</td>\n",
       "      <td>95981</td>\n",
       "      <td>104058</td>\n",
       "      <td>False</td>\n",
       "      <td>104550.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.24</td>\n",
       "      <td>91.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:342â€“440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>T477Y</td>\n",
       "      <td>mtNG_005</td>\n",
       "      <td>618</td>\n",
       "      <td>619</td>\n",
       "      <td>False</td>\n",
       "      <td>696.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.84</td>\n",
       "      <td>88.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:431â€“590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>A750R</td>\n",
       "      <td>mtNG_006</td>\n",
       "      <td>2454</td>\n",
       "      <td>2460</td>\n",
       "      <td>False</td>\n",
       "      <td>2588.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.76</td>\n",
       "      <td>94.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:573â€“767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>A1438G</td>\n",
       "      <td>mtNG_010</td>\n",
       "      <td>1683</td>\n",
       "      <td>1687</td>\n",
       "      <td>False</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.76</td>\n",
       "      <td>95.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:1278â€“1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>G3010R</td>\n",
       "      <td>mtNG_021</td>\n",
       "      <td>1282</td>\n",
       "      <td>1283</td>\n",
       "      <td>False</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.92</td>\n",
       "      <td>48.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:2925â€“3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>N3107-</td>\n",
       "      <td>mtNG_021</td>\n",
       "      <td>2420</td>\n",
       "      <td>2426</td>\n",
       "      <td>False</td>\n",
       "      <td>3812.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.75</td>\n",
       "      <td>63.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:2925â€“3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>G3407K</td>\n",
       "      <td>mtNG_023</td>\n",
       "      <td>19</td>\n",
       "      <td>488</td>\n",
       "      <td>False</td>\n",
       "      <td>493.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:3297â€“3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>A4769R</td>\n",
       "      <td>mtNG_031</td>\n",
       "      <td>388</td>\n",
       "      <td>389</td>\n",
       "      <td>False</td>\n",
       "      <td>409.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.74</td>\n",
       "      <td>94.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:4720â€“4916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>A8860G</td>\n",
       "      <td>mtNG_054</td>\n",
       "      <td>839</td>\n",
       "      <td>841</td>\n",
       "      <td>False</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.76</td>\n",
       "      <td>96.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:8680â€“8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>A15326G</td>\n",
       "      <td>mtNG_092</td>\n",
       "      <td>1375</td>\n",
       "      <td>1380</td>\n",
       "      <td>False</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.64</td>\n",
       "      <td>95.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:15256â€“15432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>T16519C</td>\n",
       "      <td>mtNG_099</td>\n",
       "      <td>3686</td>\n",
       "      <td>3696</td>\n",
       "      <td>False</td>\n",
       "      <td>3813.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.73</td>\n",
       "      <td>96.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16365â€“16523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence    marker  total  interpolated_total_coverage  \\\n",
       "4306    T152Y  mtNG_001   1956                         1958   \n",
       "749     A263R  mtNG_002   2663                         2666   \n",
       "15    -315.1c  mtNG_003   1216                         1227   \n",
       "3877      REF  mtNG_004  95981                       104058   \n",
       "4645    T477Y  mtNG_005    618                          619   \n",
       "1167    A750R  mtNG_006   2454                         2460   \n",
       "428    A1438G  mtNG_010   1683                         1687   \n",
       "3376   G3010R  mtNG_021   1282                         1283   \n",
       "3876   N3107-  mtNG_021   2420                         2426   \n",
       "3400   G3407K  mtNG_023     19                          488   \n",
       "947    A4769R  mtNG_031    388                          389   \n",
       "1273   A8860G  mtNG_054    839                          841   \n",
       "522   A15326G  mtNG_092   1375                         1380   \n",
       "4411  T16519C  mtNG_099   3686                         3696   \n",
       "\n",
       "      is_noise_or_low_frq  total_wo_noise_or_low_frq  num_markers  \\\n",
       "4306                False                     3465.0          2.0   \n",
       "749                 False                     5489.0          2.0   \n",
       "15                  False                     2573.0          1.0   \n",
       "3877                False                   104550.0         87.0   \n",
       "4645                False                      696.0          1.0   \n",
       "1167                False                     2588.0          1.0   \n",
       "428                 False                     1766.0          2.0   \n",
       "3376                False                     2627.0          1.0   \n",
       "3876                False                     3812.0          2.0   \n",
       "3400                False                      493.0          1.0   \n",
       "947                 False                      409.0          1.0   \n",
       "1273                False                      874.0          1.0   \n",
       "522                 False                     1433.0          1.0   \n",
       "4411                False                     3813.0          2.0   \n",
       "\n",
       "      variant_frequency  variant_frequency_wo_noise_or_low_frq flags  \\\n",
       "4306               99.9                                  56.45   NaN   \n",
       "749               99.89                                  48.52   NaN   \n",
       "15                 99.1                                  47.26   NaN   \n",
       "3877              92.24                                  91.80   NaN   \n",
       "4645              99.84                                  88.79   NaN   \n",
       "1167              99.76                                  94.82   NaN   \n",
       "428               99.76                                  95.30   NaN   \n",
       "3376              99.92                                  48.80   NaN   \n",
       "3876              99.75                                  63.48   NaN   \n",
       "3400               3.89                                   3.85   NaN   \n",
       "947               99.74                                  94.87   NaN   \n",
       "1273              99.76                                  96.00   NaN   \n",
       "522               99.64                                  95.95   NaN   \n",
       "4411              99.73                                  96.67   NaN   \n",
       "\n",
       "      total_mp_sum      marker_range  \n",
       "4306           NaN       chrM:19â€“155  \n",
       "749            NaN      chrM:134â€“266  \n",
       "15             NaN      chrM:260â€“368  \n",
       "3877           NaN      chrM:342â€“440  \n",
       "4645           NaN      chrM:431â€“590  \n",
       "1167           NaN      chrM:573â€“767  \n",
       "428            NaN    chrM:1278â€“1442  \n",
       "3376           NaN    chrM:2925â€“3113  \n",
       "3876           NaN    chrM:2925â€“3113  \n",
       "3400           NaN    chrM:3297â€“3487  \n",
       "947            NaN    chrM:4720â€“4916  \n",
       "1273           NaN    chrM:8680â€“8876  \n",
       "522            NaN  chrM:15256â€“15432  \n",
       "4411           NaN  chrM:16365â€“16523  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f93534-616f-438a-94e9-13e954412c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
