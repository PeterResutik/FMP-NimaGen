{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222e67c-151b-4ad5-8852-98a705f2587b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d753ada-4402-4411-b20f-44da4deeae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8d318-e797-4743-812e-cd5533ddf445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed278574-11e0-463b-a102-a1576d778a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdbb55-7981-4953-91b1-e8e57744e255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf24e84-4d95-4125-8e6f-7dee9e2ece49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652b9c2d-79d4-4d76-aac1-e26d6439b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 10: Extract numeric positions from the sequence column for sorting\n",
    "def extract_position(seq):\n",
    "    match = re.search(r\"(\\d+\\.?\\d*)\", seq)\n",
    "    return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Define function to process FDSTools SAST TSV files\n",
    "def process_fdstools_sast(file_path: str, threshold: float = 8.0):\n",
    "    IUPAC_CODES = {\n",
    "        frozenset([\"A\", \"G\"]): \"R\",\n",
    "        frozenset([\"C\", \"T\"]): \"Y\",\n",
    "        frozenset([\"A\", \"C\"]): \"M\",\n",
    "        frozenset([\"G\", \"T\"]): \"K\",\n",
    "        frozenset([\"G\", \"C\"]): \"S\",\n",
    "        frozenset([\"A\", \"T\"]): \"W\"\n",
    "    }\n",
    "\n",
    "    # Load the FDSTools SAST TSV file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "    # Convert total_mp_sum and total to numeric types\n",
    "    df[\"total_mp_sum\"] = pd.to_numeric(df[\"total_mp_sum\"], errors=\"coerce\")\n",
    "    df[\"total\"] = pd.to_numeric(df[\"total\"], errors=\"coerce\")\n",
    "\n",
    "    # Count each target (e.g. mtNG_004) and flag those with a single occurrence and low total\n",
    "    marker_counts = df[\"marker\"].value_counts()\n",
    "    single_low_coverage = df[df[\"marker\"].isin(marker_counts[marker_counts == 1].index) & (df[\"total\"] < 10)].copy()\n",
    "\n",
    "    # if not single_low_coverage.empty:\n",
    "    #     print(\"Markers with single entries and total < 10:\")\n",
    "    #     print(single_low_coverage[[\"marker\", \"sequence\", \"total\"]])\n",
    "\n",
    "    # Replace 'sequence' column with 'marker' for low-coverage targets\n",
    "    single_low_coverage[\"sequence\"] = single_low_coverage[\"marker\"]\n",
    "    single_low_coverage = single_low_coverage.drop(columns=[\"marker\"])\n",
    "    \n",
    "    # Optional: Write to CSV for external review\n",
    "    # single_low_coverage.to_csv(\"low_coverage_singleton_segments.csv\", index=False)\n",
    "\n",
    "    \n",
    "    # Step 1: Fill NaN in total and total_mp_sum with zeros\n",
    "    df[\"total\"] = df[\"total\"].fillna(0)\n",
    "    df[\"total_mp_sum\"] = df[\"total_mp_sum\"].fillna(0)\n",
    "\n",
    "    # Step 2: Flag rows with total read depth lower than threshold and low-confidence sequences\n",
    "    df[\"is_noise_or_low\"] = (df[\"sequence\"].isin([\"Other sequences\"])) | (df[\"total_mp_sum\"] < threshold)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "    \"total_mp_max\", \"forward_pct\", \"forward\", \"forward_mp_sum\",\n",
    "    \"forward_mp_max\", \"reverse\", \"reverse_mp_sum\", \"reverse_mp_max\"]\n",
    "    \n",
    "    df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "    # Merge clean_marker_total_wo_OS_THR back into the main DataFrame.\n",
    "    clean_total_per_marker = df[~df[\"is_noise_or_low\"]].groupby(\"marker\")[\"total\"].sum().rename(\"clean_marker_total_wo_OS_THR\")\n",
    "    df = df.merge(clean_total_per_marker, on=\"marker\", how=\"left\")\n",
    "\n",
    "    # Step 3: Compute normalized variant frequency (only for retained rows)\n",
    "    df[\"variant_frequency_wo_OS_THR\"] = (df[\"total\"] / df[\"clean_marker_total_wo_OS_THR\"] * 100).round(2)\n",
    "\n",
    "    # Step 5: Split multiple variants\n",
    "    df = df.assign(sequence=df[\"sequence\"].str.split())\n",
    "    df = df.explode(\"sequence\").reset_index(drop=True)\n",
    "    \n",
    "    # Step 4: Flag rows to drop\n",
    "    drop_seqs = [\"Other\", \"sequences\", \"REF\", \"N3107DEL\"]\n",
    "    df = df[(~df[\"sequence\"].isin(drop_seqs)) & (df[\"total_mp_sum\"] >= threshold)].copy()\n",
    "\n",
    "    # Step 6: Calculate estimated coverage for each row\n",
    "    df[\"estimated_total_coverage\"] = (\n",
    "        df[\"total\"] / (df[\"total_mp_sum\"] / 100)\n",
    "    ).round(0).astype(\"Int64\")\n",
    "\n",
    "    # Step 7: Group by marker + sequence to sum within same marker\n",
    "    grouped_same_marker = df.groupby([\"marker\", \"sequence\"], as_index=False).agg(\n",
    "        # total=(\"total\", \"sum\"),\n",
    "        # total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        # estimated_total_coverage=(\"estimated_total_coverage\", \"sum\")\n",
    "        total=(\"total\", \"sum\"),\n",
    "        total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        estimated_total_coverage=(\"estimated_total_coverage\", \"max\"),\n",
    "        is_noise_or_low=(\"is_noise_or_low\", \"first\"),\n",
    "        clean_marker_total_wo_OS_THR=(\"clean_marker_total_wo_OS_THR\", \"first\"),\n",
    "        variant_frequency_wo_OS_THR=(\"variant_frequency_wo_OS_THR\", \"sum\")\n",
    "    )\n",
    "    # # print(grouped_same_marker)\n",
    "    # # Step 8: Recompute variant_frequency within marker\n",
    "    # grouped_same_marker[\"variant_frequency\"] = (\n",
    "    #     grouped_same_marker[\"total\"] / grouped_same_marker[\"estimated_total_coverage\"] * 100\n",
    "    # ).round(1)\n",
    "\n",
    "    # print(grouped_same_marker)\n",
    "    \n",
    "    # Step 9: Group across markers to merge overlapping amplicons (same variant)\n",
    "    # df[\"estimated_total_coverage_across_markers\"] = (df[\"total\"] / (df[\"total_mp_sum\"] / 100)).round(0).astype(\"Int64\")\n",
    "    grouped_final = grouped_same_marker.groupby(\"sequence\", as_index=False).agg(\n",
    "        total=(\"total\", \"sum\"),\n",
    "        # total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        estimated_total_coverage=(\"estimated_total_coverage\", \"sum\"),\n",
    "        # estimated_total_coverage_across_markers=(\"estimated_total_coverage_across_markers\", \"sum\"),\n",
    "        is_noise_or_low=(\"is_noise_or_low\", \"first\"),\n",
    "        clean_marker_total_wo_OS_THR=(\"clean_marker_total_wo_OS_THR\", \"sum\"),\n",
    "        # variant_frequency_wo_OS_THR=(\"variant_frequency_wo_OS_THR\", \"sum\"),\n",
    "        num_markers=(\"marker\", \"nunique\")\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # print(grouped_final)\n",
    "    \n",
    "    grouped_final[\"variant_frequency\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"estimated_total_coverage\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    grouped_final[\"variant_frequency_wo_OS_THR\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"clean_marker_total_wo_OS_THR\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"sequence\"].apply(extract_position)\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    \n",
    "    # Step 11: Apply IUPAC codes for heteroplasmies\n",
    "    # Step 11: Apply IUPAC codes and adjust formatting for heteroplasmies\n",
    "    def resolve_heteroplasmy(row):\n",
    "        seq = row['sequence']\n",
    "    \n",
    "        # Handle deletions\n",
    "        if 'DEL' in seq:\n",
    "            return seq.replace('DEL', '-')\n",
    "\n",
    "        # Handle insertions: prefix with \"-\"\n",
    "\n",
    "        # Handle insertions / length heteroplasmies\n",
    "        if '.' in seq:\n",
    "            if row['variant_frequency_wo_OS_THR'] < 92:\n",
    "                return '-' + seq[:-1] + seq[-1].lower()  # e.g. 309.2C -> 309.2c\n",
    "            else:\n",
    "                return '-' + seq # leave as-is if frequency is high\n",
    "\n",
    "        # Handle point heteroplasmies with IUPAC\n",
    "        if row['variant_frequency_wo_OS_THR'] < 92:\n",
    "            match = re.match(r'([ACGT])(\\d+)([ACGT])', seq)\n",
    "            if not match:\n",
    "                return seq\n",
    "            ref, pos, alt = match.groups()\n",
    "            code = IUPAC_CODES.get(frozenset([ref, alt]))\n",
    "            if code:\n",
    "                return f\"{ref}{pos}{code}\"\n",
    "    \n",
    "        return seq\n",
    "\n",
    "\n",
    "\n",
    "    grouped_final['sequence'] = grouped_final.apply(resolve_heteroplasmy, axis=1)\n",
    "\n",
    "    grouped_final = pd.concat([grouped_final, single_low_coverage], ignore_index=False)\n",
    "\n",
    "    print(grouped_final)\n",
    "    \n",
    "    return grouped_final\n",
    "    # return grouped_final, df\n",
    "\n",
    "# # Placeholder path \n",
    "tsv_path = \"s23-11298-E1_S16_L001.sast.csv\"\n",
    "reference_sequence = \"../rCRS/rCRS2.fasta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bdc3b07-c7c6-4d39-8fd8-99f497e091c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markers with single entries and total < 10:\n",
      "       marker sequence  total\n",
      "499  mtNG_099  No data      0\n",
      "      sequence  total  estimated_total_coverage is_noise_or_low  \\\n",
      "7        A263G   1853                      2037           False   \n",
      "1      -309.1C    469                       588           False   \n",
      "2      -309.2c    114                       588           False   \n",
      "3      -315.1C    469                       588           False   \n",
      "11       A523-   1478                      1802           False   \n",
      "16       C524-   1478                      1802           False   \n",
      "13       A750G   2298                      2479           False   \n",
      "4       A1438G   1887                      2026           False   \n",
      "18      G3010A   2049                      2173           False   \n",
      "8       A3447M     28                       172           False   \n",
      "9       A3796G   3294                      3504           False   \n",
      "10      A4769G    927                       998           False   \n",
      "12      A6419M    192                      2015           False   \n",
      "14      A8860G   1472                      1643           False   \n",
      "5      A15326G   1917                      2137           False   \n",
      "17     G16129A    230                       291           False   \n",
      "6      A16183C    230                       291           False   \n",
      "19     T16189Y    198                       290           False   \n",
      "20     T16189-     32                       291           False   \n",
      "0    -16193.1c     95                       290           False   \n",
      "15     C16355T    639                       686           False   \n",
      "21     T16356C    639                       686           False   \n",
      "22     T16362C    639                       686           False   \n",
      "23     T16519C   1738                      1824           False   \n",
      "499   mtNG_099      0                      <NA>             NaN   \n",
      "\n",
      "     clean_marker_total_wo_OS_THR  num_markers  variant_frequency  \\\n",
      "7                          1853.0          2.0               91.0   \n",
      "1                           469.0          1.0               79.8   \n",
      "2                           469.0          1.0               19.4   \n",
      "3                           469.0          1.0               79.8   \n",
      "11                         1478.0          1.0               82.0   \n",
      "16                         1478.0          1.0               82.0   \n",
      "13                         2298.0          1.0               92.7   \n",
      "4                          1887.0          2.0               93.1   \n",
      "18                         2049.0          1.0               94.3   \n",
      "8                            49.0          1.0               16.3   \n",
      "9                          3294.0          1.0               94.0   \n",
      "10                          927.0          1.0               92.9   \n",
      "12                         1850.0          1.0                9.5   \n",
      "14                         1472.0          1.0               89.6   \n",
      "5                          1917.0          1.0               89.7   \n",
      "17                          230.0          1.0               79.0   \n",
      "6                           230.0          1.0               79.0   \n",
      "19                          230.0          1.0               68.3   \n",
      "20                          230.0          1.0               11.0   \n",
      "0                           230.0          1.0               32.8   \n",
      "15                          639.0          1.0               93.1   \n",
      "21                          639.0          1.0               93.1   \n",
      "22                          639.0          1.0               93.1   \n",
      "23                         1738.0          1.0               95.3   \n",
      "499                           NaN          NaN               <NA>   \n",
      "\n",
      "     variant_frequency_wo_OS_THR flags  total_mp_sum total_mp_max forward_pct  \\\n",
      "7                          100.0   NaN           NaN          NaN         NaN   \n",
      "1                          100.0   NaN           NaN          NaN         NaN   \n",
      "2                           24.3   NaN           NaN          NaN         NaN   \n",
      "3                          100.0   NaN           NaN          NaN         NaN   \n",
      "11                         100.0   NaN           NaN          NaN         NaN   \n",
      "16                         100.0   NaN           NaN          NaN         NaN   \n",
      "13                         100.0   NaN           NaN          NaN         NaN   \n",
      "4                          100.0   NaN           NaN          NaN         NaN   \n",
      "18                         100.0   NaN           NaN          NaN         NaN   \n",
      "8                           57.1   NaN           NaN          NaN         NaN   \n",
      "9                          100.0   NaN           NaN          NaN         NaN   \n",
      "10                         100.0   NaN           NaN          NaN         NaN   \n",
      "12                          10.4   NaN           NaN          NaN         NaN   \n",
      "14                         100.0   NaN           NaN          NaN         NaN   \n",
      "5                          100.0   NaN           NaN          NaN         NaN   \n",
      "17                         100.0   NaN           NaN          NaN         NaN   \n",
      "6                          100.0   NaN           NaN          NaN         NaN   \n",
      "19                          86.1   NaN           NaN          NaN         NaN   \n",
      "20                          13.9   NaN           NaN          NaN         NaN   \n",
      "0                           41.3   NaN           NaN          NaN         NaN   \n",
      "15                         100.0   NaN           NaN          NaN         NaN   \n",
      "21                         100.0   NaN           NaN          NaN         NaN   \n",
      "22                         100.0   NaN           NaN          NaN         NaN   \n",
      "23                         100.0   NaN           NaN          NaN         NaN   \n",
      "499                          NaN   NaN           0.0         0.00        0.00   \n",
      "\n",
      "    forward forward_mp_sum forward_mp_max reverse reverse_mp_sum  \\\n",
      "7       NaN            NaN            NaN     NaN            NaN   \n",
      "1       NaN            NaN            NaN     NaN            NaN   \n",
      "2       NaN            NaN            NaN     NaN            NaN   \n",
      "3       NaN            NaN            NaN     NaN            NaN   \n",
      "11      NaN            NaN            NaN     NaN            NaN   \n",
      "16      NaN            NaN            NaN     NaN            NaN   \n",
      "13      NaN            NaN            NaN     NaN            NaN   \n",
      "4       NaN            NaN            NaN     NaN            NaN   \n",
      "18      NaN            NaN            NaN     NaN            NaN   \n",
      "8       NaN            NaN            NaN     NaN            NaN   \n",
      "9       NaN            NaN            NaN     NaN            NaN   \n",
      "10      NaN            NaN            NaN     NaN            NaN   \n",
      "12      NaN            NaN            NaN     NaN            NaN   \n",
      "14      NaN            NaN            NaN     NaN            NaN   \n",
      "5       NaN            NaN            NaN     NaN            NaN   \n",
      "17      NaN            NaN            NaN     NaN            NaN   \n",
      "6       NaN            NaN            NaN     NaN            NaN   \n",
      "19      NaN            NaN            NaN     NaN            NaN   \n",
      "20      NaN            NaN            NaN     NaN            NaN   \n",
      "0       NaN            NaN            NaN     NaN            NaN   \n",
      "15      NaN            NaN            NaN     NaN            NaN   \n",
      "21      NaN            NaN            NaN     NaN            NaN   \n",
      "22      NaN            NaN            NaN     NaN            NaN   \n",
      "23      NaN            NaN            NaN     NaN            NaN   \n",
      "499       0           0.00           0.00       0           0.00   \n",
      "\n",
      "    reverse_mp_max  \n",
      "7              NaN  \n",
      "1              NaN  \n",
      "2              NaN  \n",
      "3              NaN  \n",
      "11             NaN  \n",
      "16             NaN  \n",
      "13             NaN  \n",
      "4              NaN  \n",
      "18             NaN  \n",
      "8              NaN  \n",
      "9              NaN  \n",
      "10             NaN  \n",
      "12             NaN  \n",
      "14             NaN  \n",
      "5              NaN  \n",
      "17             NaN  \n",
      "6              NaN  \n",
      "19             NaN  \n",
      "20             NaN  \n",
      "0              NaN  \n",
      "15             NaN  \n",
      "21             NaN  \n",
      "22             NaN  \n",
      "23             NaN  \n",
      "499           0.00  \n"
     ]
    }
   ],
   "source": [
    "processed_df = process_fdstools_sast(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8182ec-9d6b-4f0d-b830-4fe3593c2cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "26acfdb6-5ab7-4b40-8705-0805a718664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"s23-11303-E1_S13_L001_processed10.txt\" \n",
    "processed_df.to_csv(output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2980e6-7cf1-4f9c-bf97-d0aa67debcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5888a8a7-917d-4624-9c79-df85c494882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def process_empop_variant_table(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a variant table with EMPOP-style variant annotations.\n",
    "    - Splits multi-variant rows\n",
    "    - Sums VariantLevel and allele-specific Coverage\n",
    "    - Keeps the first value of MeanBaseQuality\n",
    "    - Sorts variants by position\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: path to the tab-separated file\n",
    "\n",
    "    Returns:\n",
    "    - A cleaned and sorted DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Load file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    # Split EMPOP_Variant column and explode into rows\n",
    "    df[\"EMPOP_Variant\"] = df[\"EMPOP_Variant\"].astype(str).str.split()\n",
    "    df = df.explode(\"EMPOP_Variant\").reset_index(drop=True)\n",
    "\n",
    "    # Convert numeric columns\n",
    "    df[\"VariantLevel\"] = pd.to_numeric(df[\"VariantLevel\"], errors=\"coerce\")\n",
    "\n",
    "    # Helper: sum comma-separated numbers elementwise\n",
    "    def add_comma_separated_numbers(series):\n",
    "        split_lists = series.dropna().astype(str).apply(lambda x: list(map(float, x.split(','))))\n",
    "        if split_lists.empty:\n",
    "            return \"\"\n",
    "        summed = [sum(x) for x in zip(*split_lists)]\n",
    "        return \",\".join(f\"{s:.4g}\" for s in summed)\n",
    "\n",
    "    # Aggregate\n",
    "    group_keys = [\"EMPOP_Variant\"]\n",
    "    numeric_agg = {\n",
    "        \"VariantLevel\": \"sum\",\n",
    "        \"Coverage\": add_comma_separated_numbers,\n",
    "        \"MeanBaseQuality\": \"first\"\n",
    "    }\n",
    "    other_cols = [col for col in df.columns if col not in numeric_agg and col not in group_keys]\n",
    "    full_agg = {**numeric_agg, **{col: \"first\" for col in other_cols}}\n",
    "\n",
    "    grouped = df.groupby(group_keys, as_index=False).agg(full_agg)\n",
    "\n",
    "    # Sort by numeric position extracted from variant\n",
    "    def extract_position(variant):\n",
    "        match = re.search(r\"(\\d+\\.?\\d*)\", str(variant))\n",
    "        return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "    grouped[\"position\"] = grouped[\"EMPOP_Variant\"].apply(extract_position)\n",
    "    grouped = grouped.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    def correct_length_het_case(row):\n",
    "        if \".\" in row[\"EMPOP_Variant\"] and row[\"VariantLevel\"] >= 0.92:\n",
    "            return row[\"EMPOP_Variant\"][:-1] + row[\"EMPOP_Variant\"][-1].upper()\n",
    "        return row[\"EMPOP_Variant\"]\n",
    "\n",
    "    grouped[\"EMPOP_Variant\"] = grouped.apply(correct_length_het_case, axis=1)\n",
    "    \n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ceafbc3a-056a-4ff3-9630-2023599d465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop.txt\"\n",
    "grouped_variants = process_empop_variant_table(input_path)\n",
    "\n",
    "# Save results\n",
    "grouped_variants.to_csv(\"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop_grouped.txt\", sep=\"\\t\", index=False)\n",
    "# exploded_df.to_csv(\"exploded_variants.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ead507-3231-44e9-9958-d9b5ea95c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned = process_empop_variant_table(\"your_input_file.tsv\")\n",
    "# df_cleaned.to_csv(\"cleaned_empop_variants.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0e857020-4262-408c-a6c4-38158868ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def merge_variant_callers(file1: str, file2: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges two variant tables from different callers on their variant column.\n",
    "    \n",
    "    Parameters:\n",
    "        file1: Path to the first variant caller table (expects 'sequence' column)\n",
    "        file2: Path to the second variant caller table (expects 'EMPOP_Variant' column)\n",
    "        \n",
    "    Returns:\n",
    "        A merged DataFrame with flags and full column preservation, sorted by position.\n",
    "    \"\"\"\n",
    "    # Load both files\n",
    "    df1 = pd.read_csv(file1, sep=\"\\t\")\n",
    "    df2 = pd.read_csv(file2, sep=\"\\t\")\n",
    "    \n",
    "    # Rename variant columns to common key\n",
    "    df1 = df1.rename(columns={\"sequence\": \"variant\"})\n",
    "    df2 = df2.rename(columns={\"EMPOP_Variant\": \"variant\"})\n",
    "    \n",
    "    # Merge the dataframes on the variant column\n",
    "    merged = pd.merge(df1, df2, on=\"variant\", how=\"outer\", suffixes=(\"_vc1\", \"_vc2\"))\n",
    "\n",
    "    # Add flags for presence in each caller\n",
    "    merged[\"called_in_vc1\"] = ~merged[\"total\"].isna()\n",
    "    merged[\"called_in_vc2\"] = ~merged[\"VariantLevel\"].isna()\n",
    "\n",
    "    # Extract numeric position for sorting\n",
    "    def extract_position(seq):\n",
    "        match = re.search(r\"(\\d+\\.?\\d*)\", str(seq))\n",
    "        return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "    merged[\"variant_position\"] = merged[\"variant\"].apply(extract_position)\n",
    "    merged = merged.sort_values(by=\"variant_position\").drop(columns=[\"variant_position\"])\n",
    "\n",
    "    # Reorder columns for clarity\n",
    "    front = [\"variant\", \"called_in_vc1\", \"called_in_vc2\"]\n",
    "    other = [col for col in merged.columns if col not in front]\n",
    "    merged = merged[front + other]\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4acd3a2d-f8c8-498c-9ad8-7742f5e4dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_variant_callers(\"s23-11303-E1_S13_L001_processed10.txt\",\"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop_grouped.txt\")\n",
    "df_merged.to_csv(\"merged_variants2.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "84e5529b-129d-4f2e-9171-66cd7ddd067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Step 10: Extract numeric positions from the sequence column for sorting\n",
    "def extract_position(seq):\n",
    "    match = re.search(r\"(\\d+\\.?\\d*)\", seq)\n",
    "    return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Step 11: Apply IUPAC codes and adjust formatting for heteroplasmies\n",
    "def resolve_heteroplasmy(row, min_variant_frequency_pct, length_heteroplasmy_threshold, IUPAC_CODES):\n",
    "    seq = row['sequence']\n",
    "\n",
    "    # Handle deletions\n",
    "    if 'DEL' in seq:\n",
    "        return seq.replace('DEL', '-')\n",
    "\n",
    "    # Handle insertions / length heteroplasmies\n",
    "    if '.' in seq:\n",
    "        if row['variant_frequency'] < length_heteroplasmy_threshold:\n",
    "            return '-' + seq[:-1] + seq[-1].lower()  # e.g. 309.2C -> 309.2c\n",
    "        else:\n",
    "            return '-' + seq # leave as-is if frequency is high\n",
    "\n",
    "    # Handle point heteroplasmies with IUPAC\n",
    "    if row['variant_frequency'] < 100-min_variant_frequency_pct:\n",
    "        match = re.match(r'([ACGT])(\\d+)([ACGT])', seq)\n",
    "        if not match:\n",
    "            return seq\n",
    "        ref, pos, alt = match.groups()\n",
    "        code = IUPAC_CODES.get(frozenset([ref, alt]))\n",
    "        if code:\n",
    "            return f\"{ref}{pos}{code}\"\n",
    "\n",
    "    return seq\n",
    "\n",
    "def load_marker_ranges(filepath):\n",
    "    marker_ranges = {}\n",
    "    in_position_block = False\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"[genome_position]\"):\n",
    "                in_position_block = True\n",
    "                continue\n",
    "            if line.startswith(\"[\") and in_position_block:\n",
    "                # Stop if another block begins\n",
    "                break\n",
    "            if in_position_block and \"=\" in line:\n",
    "                marker, values = line.split(\"=\")\n",
    "                marker = marker.strip()\n",
    "                parts = [v.strip() for v in values.split(\",\")]\n",
    "                if len(parts) >= 3:\n",
    "                    chrom, start, end = parts[:3]\n",
    "                    marker_ranges[marker] = f\"{chrom}:{start}–{end}\"\n",
    "    return marker_ranges\n",
    "\n",
    "# Define function to process FDSTools SAST TSV files\n",
    "def process_fdstools_sast(file_path: str, min_variant_frequency_pct: float = 5.0, depth_threshold: int = 10, length_heteroplasmy_threshold: float = 90.0):\n",
    "    IUPAC_CODES = {\n",
    "        frozenset([\"A\", \"G\"]): \"R\",\n",
    "        frozenset([\"C\", \"T\"]): \"Y\",\n",
    "        frozenset([\"A\", \"C\"]): \"M\",\n",
    "        frozenset([\"G\", \"T\"]): \"K\",\n",
    "        frozenset([\"G\", \"C\"]): \"S\",\n",
    "        frozenset([\"A\", \"T\"]): \"W\"\n",
    "    }\n",
    "\n",
    "    # Load the FDSTools SAST TSV file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "    \"total_mp_max\", \"forward_pct\", \"forward\", \"forward_mp_sum\",\n",
    "    \"forward_mp_max\", \"reverse\", \"reverse_mp_sum\", \"reverse_mp_max\"]\n",
    "    \n",
    "    df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "    \n",
    "    # # Convert total_mp_sum and total to numeric types\n",
    "    df[\"total_mp_sum\"] = pd.to_numeric(df[\"total_mp_sum\"], errors=\"coerce\")\n",
    "    df[\"total\"] = pd.to_numeric(df[\"total\"], errors=\"coerce\")\n",
    "\n",
    "    # Count each marker (e.g. mtNG_001 or mtNG_007) and flag those with a single occurrence and low total\n",
    "    marker_counts = df[\"marker\"].value_counts()\n",
    "    # print(marker_counts)\n",
    "    single_low_coverage = df[df[\"marker\"].isin(marker_counts[marker_counts == 1].index) & (df[\"total\"] < depth_threshold)].copy()\n",
    "    print(single_low_coverage)\n",
    "    \n",
    "    # Step 1: Fill NaN in total and total_mp_sum with zeros\n",
    "    df[\"total\"] = df[\"total\"].fillna(0)\n",
    "    df[\"total_mp_sum\"] = df[\"total_mp_sum\"].fillna(0)\n",
    "\n",
    "    # df = df[df[\"marker\"] == \"mtNG_005\"]    \n",
    "    # df = df[df[\"marker\"].isin([\"mtNG_001\", \"mtNG_002\"])]\n",
    "    # Step 2: Flag rows with total read depth lower than threshold and low-confidence sequences\n",
    "    # df[\"is_noise_or_low_frq\"] = (df[\"sequence\"].isin([\"Other sequences\"])) & (df[\"total_mp_sum\"] < 0)\n",
    " \n",
    "\n",
    "    # Step 5: Split multiple variants\n",
    "    df = df.assign(sequence=df[\"sequence\"].str.split())\n",
    "    df = df.explode(\"sequence\").reset_index(drop=True)\n",
    "    print(df)\n",
    "    \n",
    "    # Merge clean_marker_total_wo_OS_THR back into the main DataFrame.\n",
    "    # clean_total_per_marker = df[~df[\"is_noise_or_low_frq\"]].groupby(\"marker\")[\"total\"].sum().rename(\"total_wo_noise_or_low_frq\")\n",
    "    # print(clean_total_per_marker)\n",
    "    # df = df.merge(clean_total_per_marker, on=\"marker\", how=\"left\")    \n",
    "\n",
    "    # Step 3: Compute normalized variant frequency (only for retained rows)\n",
    "    # df[\"variant_frequency_wo_noise_or_low_frq\"] = (df[\"total\"] / df[\"total_wo_noise_or_low_frq\"] * 100).round(2)\n",
    "    # print(df)\n",
    "\n",
    "\n",
    "    # # Step 4: Flag rows to drop LETS THINK ABOUT THIS, WHEN IS THE BEST TIME TO FILTER THESE OUT?\n",
    "    # drop_seqs = [\"Other\", \"sequences\", \"REF\", \"N3107DEL\"]\n",
    "    # df = df[(~df[\"sequence\"].isin(drop_seqs)) & (df[\"total_mp_sum\"] >= min_variant_frequency_pct)].copy()\n",
    "\n",
    "    \n",
    "    df[\"interpolated_total_coverage\"] = (np.ceil(df[\"total\"] / (df[\"total_mp_sum\"] / 100))).astype(\"Int64\")\n",
    "\n",
    "    # Step 7: Group by marker + sequence to sum within same marker\n",
    "    grouped_same_marker = df.groupby([\"marker\", \"sequence\"], as_index=False).agg(\n",
    "        total=(\"total\", \"sum\"),\n",
    "        total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        interpolated_total_coverage=(\"interpolated_total_coverage\", \"max\"),\n",
    "        # is_noise_or_low_frq=(\"is_noise_or_low_frq\", \"first\"),\n",
    "        # total_wo_noise_or_low_frq=(\"total_wo_noise_or_low_frq\", \"first\"),\n",
    "        # variant_frequency_wo_noise_or_low_frq=(\"variant_frequency_wo_noise_or_low_frq\", \"sum\")\n",
    "    )\n",
    "    # print(grouped_same_marker)\n",
    "\n",
    "    # Extract \"Other\" sequence coverage per marker\n",
    "    other_per_marker = grouped_same_marker[grouped_same_marker[\"sequence\"] == \"Other\"][[\"marker\", \"total\"]]\n",
    "    other_per_marker = other_per_marker.rename(columns={\"total\": \"other_coverage\"})\n",
    "    print(other_per_marker)\n",
    "    # Merge with grouped data\n",
    "    grouped_same_marker = grouped_same_marker.merge(other_per_marker, on=\"marker\", how=\"left\")\n",
    "    grouped_same_marker[\"other_coverage\"] = grouped_same_marker[\"other_coverage\"].fillna(0)\n",
    "    # print(grouped_same_marker)\n",
    "\n",
    "    # Subtract \"Other\" sequence coverage from interpolated_total_coverage\n",
    "    grouped_same_marker[\"adjusted_coverage\"] = grouped_same_marker[\"interpolated_total_coverage\"] - grouped_same_marker[\"other_coverage\"]\n",
    "    \n",
    "    # Ensure adjusted coverage is not negative or zero (to avoid division by zero)\n",
    "    grouped_same_marker[\"adjusted_coverage\"] = grouped_same_marker[\"adjusted_coverage\"].clip(lower=1)\n",
    "\n",
    "    \n",
    "    # # Step 9: Group across markers to merge overlapping amplicons (same variant)\n",
    "    grouped_final = grouped_same_marker.groupby(\"sequence\", as_index=False).agg(\n",
    "        marker=(\"marker\", \"first\"),\n",
    "        total=(\"total\", \"sum\"),\n",
    "        adjusted_coverage=(\"adjusted_coverage\", \"sum\"),\n",
    "        # is_noise_or_low_frq=(\"is_noise_or_low_frq\", \"first\"),\n",
    "        # total_wo_noise_or_low_frq=(\"total_wo_noise_or_low_frq\", \"sum\"),\n",
    "        num_markers=(\"marker\", \"nunique\")\n",
    "    )\n",
    "    # print(grouped_same_marker)\n",
    "    \n",
    "    \n",
    "    grouped_final[\"variant_frequency\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"adjusted_coverage\"] * 100\n",
    "    ).round(2)\n",
    "\n",
    "    # grouped_final[\"variant_frequency_wo_noise_or_low_frq\"] = (\n",
    "    #     grouped_final[\"total\"] / grouped_final[\"total_wo_noise_or_low_frq\"] * 100\n",
    "    # ).round(2)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"sequence\"].apply(extract_position)\n",
    "    # grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    drop_seqs = [\"Other\", \"sequences\", \"REF\", \"N3107DEL\"]\n",
    "    grouped_final = grouped_final[(~grouped_final[\"sequence\"].isin(drop_seqs))]\n",
    "    \n",
    "    grouped_final[\"is_noise_or_low_frq\"] = (grouped_final[\"sequence\"].isin([\"Other sequences\"])) | (grouped_final[\"variant_frequency\"] < 3)\n",
    "    grouped_final = grouped_final[~grouped_final[\"is_noise_or_low_frq\"]]\n",
    "    print(grouped_final)\n",
    "    # print(grouped_final)\n",
    "    # Temporary store for merged entries\n",
    "    merged_rows = []\n",
    "    used_indices = set()\n",
    "\n",
    "    for pos, group in grouped_final.groupby(\"position\"):\n",
    "        if group.shape[0] != 2:\n",
    "            continue\n",
    "\n",
    "        # Identify deletion and substitution\n",
    "        del_row = group[group[\"sequence\"].str.endswith(\"DEL\")]\n",
    "        # print(del_row)\n",
    "        sub_row = group[~group[\"sequence\"].str.endswith(\"DEL\")]\n",
    "        # print(sub_row)\n",
    "        \n",
    "        if del_row.empty or sub_row.empty:\n",
    "            continue\n",
    "    \n",
    "        del_idx = del_row.index[0]\n",
    "        # print(del_idx)\n",
    "        sub_idx = sub_row.index[0]\n",
    "    \n",
    "        # Skip if already merged\n",
    "        if del_idx in used_indices or sub_idx in used_indices:\n",
    "            continue\n",
    "    \n",
    "        # Merge logic\n",
    "        # if del_row[\"total\"].iloc[0] >= sub_row[\"total\"].iloc[0]:\n",
    "        #     dominant_row = del_row.iloc[0]\n",
    "        # else:\n",
    "        #     dominant_row = sub_row.iloc[0]\n",
    "        total = del_row[\"total\"].iloc[0] + sub_row[\"total\"].iloc[0]\n",
    "        coverage = del_row[\"total_wo_noise_or_low_frq\"].iloc[0] \n",
    "        freq = round(total / coverage * 100, 1) if coverage else 0\n",
    "        \n",
    "        sub_seq = sub_row[\"sequence\"].iloc[0]\n",
    "        ref, pos_str, alt = re.match(r'([ACGT])(\\d+)([ACGT])', sub_seq).groups()\n",
    "    \n",
    "        # If deletion is the minor variant, return lowercase\n",
    "        # del_freq = del_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "        merged_seq = f\"{ref}{pos_str}{alt.lower()}\" if del_freq < (length_heteroplasmy_threshold) else f\"{ref}{pos_str}{alt}\"\n",
    "\n",
    "        sub_freq = sub_row[\"variant_frequency\"].iloc[0]\n",
    "        # sub_clean_freq = sub_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "        del_freq = del_row[\"variant_frequency\"].iloc[0]\n",
    "        # del_clean_freq = del_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "    \n",
    "        freq_annotation = (\n",
    "            f\"sub:{sub_freq} ({sub_clean_freq}) | \"\n",
    "            f\"del:{del_freq} ({del_clean_freq})\"\n",
    "        )\n",
    "        merged_rows.append({\n",
    "            \"sequence\": merged_seq,\n",
    "            \"total\": total,\n",
    "            \"adjusted_coverage\": del_row[\"adjusted_coverage\"].iloc[0],\n",
    "            \"is_noise_or_low_frq\": False,\n",
    "            \"total_wo_noise_or_low_frq\": total,  # fallback\n",
    "            \"num_markers\": f\"sub:{sub_row['num_markers'].iloc[0]} | del:{del_row['num_markers'].iloc[0]}\", \n",
    "            \"variant_frequency\": freq_annotation, \n",
    "            \"variant_frequency_wo_noise_or_low_frq\": freq,\n",
    "            \"marker\": sub_row[\"marker\"].iloc[0],  # arbitrary\n",
    "            \"position\": float(pos)\n",
    "        })\n",
    "    \n",
    "        used_indices.update([del_idx, sub_idx])\n",
    "\n",
    "    # Drop merged ones and add new merged row\n",
    "    grouped_final = grouped_final.drop(index=used_indices)\n",
    "    if merged_rows:\n",
    "        grouped_final = pd.concat([grouped_final, pd.DataFrame(merged_rows)], ignore_index=True)\n",
    "\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    grouped_final[\"sequence\"] = grouped_final.apply(\n",
    "        lambda row: resolve_heteroplasmy(\n",
    "            row,\n",
    "            min_variant_frequency_pct,\n",
    "            length_heteroplasmy_threshold,\n",
    "            IUPAC_CODES\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    grouped_final = pd.concat([grouped_final, single_low_coverage], ignore_index=False)\n",
    "\n",
    "    # Load the mapping from your txt file\n",
    "    marker_to_range = load_marker_ranges(\"mtNG_lib2_v211-flank.txt\")\n",
    "    grouped_final[\"marker_range\"] = grouped_final[\"marker\"].map(marker_to_range)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"marker\"].apply(extract_position)\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    return grouped_final\n",
    "\n",
    "tsv_path = \"2800M_L001.sast.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "02f41175-d116-4974-84ae-64500657e78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [marker, sequence, flags, total, total_mp_sum]\n",
      "Index: []\n",
      "        marker sequence   flags  total  total_mp_sum\n",
      "0     mtNG_001    T152C  allele    492       94.8000\n",
      "1     mtNG_001     G97T     NaN      4        0.7710\n",
      "2     mtNG_001    T152C     NaN      4        0.7710\n",
      "3     mtNG_001   C19DEL     NaN      1        0.1930\n",
      "4     mtNG_001    T152C     NaN      1        0.1930\n",
      "...        ...      ...     ...    ...           ...\n",
      "6212  mtNG_100  C16478A     NaN      1        0.0315\n",
      "6213  mtNG_100  T16519C     NaN      1        0.0315\n",
      "6214  mtNG_100  T16475C     NaN      1        0.0315\n",
      "6215  mtNG_100  G16516T     NaN      1        0.0315\n",
      "6216  mtNG_100  T16519A     NaN      1        0.0315\n",
      "\n",
      "[6217 rows x 5 columns]\n",
      "Empty DataFrame\n",
      "Columns: [marker, other_coverage]\n",
      "Index: []\n",
      "        marker sequence  total  total_mp_sum  interpolated_total_coverage  \\\n",
      "0     mtNG_001    A148T      1        0.1930                          519   \n",
      "1     mtNG_001     A87G      1        0.1930                          519   \n",
      "2     mtNG_001     A95C      1        0.1930                          519   \n",
      "3     mtNG_001    C113T      1        0.1930                          519   \n",
      "4     mtNG_001  C114DEL      1        0.1930                          519   \n",
      "...        ...      ...    ...           ...                          ...   \n",
      "5171  mtNG_100  T16568C      1        0.0315                         3175   \n",
      "5172  mtNG_100     T20A      1        0.0315                         3175   \n",
      "5173  mtNG_100     T23A      1        0.0315                         3175   \n",
      "5174  mtNG_100     T30C      1        0.0315                         3175   \n",
      "5175  mtNG_100      T3C      1        0.0315                         3175   \n",
      "\n",
      "      other_coverage  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "...              ...  \n",
      "5171               0  \n",
      "5172               0  \n",
      "5173               0  \n",
      "5174               0  \n",
      "5175               0  \n",
      "\n",
      "[5176 rows x 6 columns]\n",
      "     sequence    marker  total  interpolated_total_coverage  num_markers  \\\n",
      "15     315.1C  mtNG_003   1216                         1227            1   \n",
      "428    A1438G  mtNG_010   1683                         1687            2   \n",
      "522   A15326G  mtNG_092   1375                         1380            1   \n",
      "749     A263G  mtNG_002   2663                         2666            2   \n",
      "947    A4769G  mtNG_031    388                          389            1   \n",
      "1167    A750G  mtNG_006   2454                         2460            1   \n",
      "1273   A8860G  mtNG_054    839                          841            1   \n",
      "3376   G3010A  mtNG_021   1282                         1283            1   \n",
      "3400   G3407T  mtNG_023     19                          488            1   \n",
      "4306    T152C  mtNG_001   1956                         1958            2   \n",
      "4411  T16519C  mtNG_099   3686                         3696            2   \n",
      "4645    T477C  mtNG_005    618                          619            1   \n",
      "\n",
      "      variant_frequency  position  is_noise_or_low_frq  \n",
      "15                 99.1     315.1                False  \n",
      "428               99.76    1438.0                False  \n",
      "522               99.64   15326.0                False  \n",
      "749               99.89     263.0                False  \n",
      "947               99.74    4769.0                False  \n",
      "1167              99.76     750.0                False  \n",
      "1273              99.76    8860.0                False  \n",
      "3376              99.92    3010.0                False  \n",
      "3400               3.89    3407.0                False  \n",
      "4306               99.9     152.0                False  \n",
      "4411              99.73   16519.0                False  \n",
      "4645              99.84     477.0                False  \n"
     ]
    }
   ],
   "source": [
    "processed_df = process_fdstools_sast(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f5320130-1b8c-46e0-8a57-d151a566aad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>marker</th>\n",
       "      <th>total</th>\n",
       "      <th>interpolated_total_coverage</th>\n",
       "      <th>num_markers</th>\n",
       "      <th>variant_frequency</th>\n",
       "      <th>is_noise_or_low_frq</th>\n",
       "      <th>flags</th>\n",
       "      <th>total_mp_sum</th>\n",
       "      <th>marker_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>T152C</td>\n",
       "      <td>mtNG_001</td>\n",
       "      <td>1956</td>\n",
       "      <td>1958</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:19–155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>A263G</td>\n",
       "      <td>mtNG_002</td>\n",
       "      <td>2663</td>\n",
       "      <td>2666</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.89</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:134–266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-315.1C</td>\n",
       "      <td>mtNG_003</td>\n",
       "      <td>1216</td>\n",
       "      <td>1227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:260–368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>T477C</td>\n",
       "      <td>mtNG_005</td>\n",
       "      <td>618</td>\n",
       "      <td>619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.84</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:431–590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>A750G</td>\n",
       "      <td>mtNG_006</td>\n",
       "      <td>2454</td>\n",
       "      <td>2460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.76</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:573–767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>A1438G</td>\n",
       "      <td>mtNG_010</td>\n",
       "      <td>1683</td>\n",
       "      <td>1687</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.76</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:1278–1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>G3010A</td>\n",
       "      <td>mtNG_021</td>\n",
       "      <td>1282</td>\n",
       "      <td>1283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.92</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:2925–3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>G3407K</td>\n",
       "      <td>mtNG_023</td>\n",
       "      <td>19</td>\n",
       "      <td>488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:3297–3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>A4769G</td>\n",
       "      <td>mtNG_031</td>\n",
       "      <td>388</td>\n",
       "      <td>389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.74</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:4720–4916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>A8860G</td>\n",
       "      <td>mtNG_054</td>\n",
       "      <td>839</td>\n",
       "      <td>841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.76</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:8680–8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>A15326G</td>\n",
       "      <td>mtNG_092</td>\n",
       "      <td>1375</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.64</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:15256–15432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>T16519C</td>\n",
       "      <td>mtNG_099</td>\n",
       "      <td>3686</td>\n",
       "      <td>3696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.73</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16365–16523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence    marker  total  interpolated_total_coverage  num_markers  \\\n",
       "4306    T152C  mtNG_001   1956                         1958          2.0   \n",
       "749     A263G  mtNG_002   2663                         2666          2.0   \n",
       "15    -315.1C  mtNG_003   1216                         1227          1.0   \n",
       "4645    T477C  mtNG_005    618                          619          1.0   \n",
       "1167    A750G  mtNG_006   2454                         2460          1.0   \n",
       "428    A1438G  mtNG_010   1683                         1687          2.0   \n",
       "3376   G3010A  mtNG_021   1282                         1283          1.0   \n",
       "3400   G3407K  mtNG_023     19                          488          1.0   \n",
       "947    A4769G  mtNG_031    388                          389          1.0   \n",
       "1273   A8860G  mtNG_054    839                          841          1.0   \n",
       "522   A15326G  mtNG_092   1375                         1380          1.0   \n",
       "4411  T16519C  mtNG_099   3686                         3696          2.0   \n",
       "\n",
       "      variant_frequency  is_noise_or_low_frq flags  total_mp_sum  \\\n",
       "4306               99.9                False   NaN           NaN   \n",
       "749               99.89                False   NaN           NaN   \n",
       "15                 99.1                False   NaN           NaN   \n",
       "4645              99.84                False   NaN           NaN   \n",
       "1167              99.76                False   NaN           NaN   \n",
       "428               99.76                False   NaN           NaN   \n",
       "3376              99.92                False   NaN           NaN   \n",
       "3400               3.89                False   NaN           NaN   \n",
       "947               99.74                False   NaN           NaN   \n",
       "1273              99.76                False   NaN           NaN   \n",
       "522               99.64                False   NaN           NaN   \n",
       "4411              99.73                False   NaN           NaN   \n",
       "\n",
       "          marker_range  \n",
       "4306       chrM:19–155  \n",
       "749       chrM:134–266  \n",
       "15        chrM:260–368  \n",
       "4645      chrM:431–590  \n",
       "1167      chrM:573–767  \n",
       "428     chrM:1278–1442  \n",
       "3376    chrM:2925–3113  \n",
       "3400    chrM:3297–3487  \n",
       "947     chrM:4720–4916  \n",
       "1273    chrM:8680–8876  \n",
       "522   chrM:15256–15432  \n",
       "4411  chrM:16365–16523  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f93534-616f-438a-94e9-13e954412c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
