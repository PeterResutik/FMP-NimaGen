{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222e67c-151b-4ad5-8852-98a705f2587b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d753ada-4402-4411-b20f-44da4deeae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8d318-e797-4743-812e-cd5533ddf445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed278574-11e0-463b-a102-a1576d778a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdbb55-7981-4953-91b1-e8e57744e255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf24e84-4d95-4125-8e6f-7dee9e2ece49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "652b9c2d-79d4-4d76-aac1-e26d6439b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 10: Extract numeric positions from the sequence column for sorting\n",
    "def extract_position(seq):\n",
    "    match = re.search(r\"(\\d+\\.?\\d*)\", seq)\n",
    "    return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Define function to process FDSTools SAST TSV files\n",
    "def process_fdstools_sast(file_path: str, threshold: float = 8.0):\n",
    "    IUPAC_CODES = {\n",
    "        frozenset([\"A\", \"G\"]): \"R\",\n",
    "        frozenset([\"C\", \"T\"]): \"Y\",\n",
    "        frozenset([\"A\", \"C\"]): \"M\",\n",
    "        frozenset([\"G\", \"T\"]): \"K\",\n",
    "        frozenset([\"G\", \"C\"]): \"S\",\n",
    "        frozenset([\"A\", \"T\"]): \"W\"\n",
    "    }\n",
    "\n",
    "    # Load the FDSTools SAST TSV file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)\n",
    "    df[\"total_mp_sum\"] = pd.to_numeric(df[\"total_mp_sum\"], errors=\"coerce\")\n",
    "    df[\"total\"] = pd.to_numeric(df[\"total\"], errors=\"coerce\")\n",
    "\n",
    "    # Step 1: Calculate total read depth per marker\n",
    "    df[\"total\"] = df[\"total\"].fillna(0)\n",
    "    df[\"total_mp_sum\"] = df[\"total_mp_sum\"].fillna(0)\n",
    "\n",
    "    # Step 2: Recalculate total read depth per marker excluding noise and low-confidence\n",
    "    df[\"is_noise_or_low\"] = (df[\"sequence\"].isin([\"Other sequences\"])) | (df[\"total_mp_sum\"] < threshold)\n",
    "\n",
    "    columns_to_drop = [\n",
    "    \"total_mp_max\", \"forward_pct\", \"forward\", \"forward_mp_sum\",\n",
    "    \"forward_mp_max\", \"reverse\", \"reverse_mp_sum\", \"reverse_mp_max\"\n",
    "    ]\n",
    "\n",
    "    df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "    \n",
    "    clean_total_per_marker = df[~df[\"is_noise_or_low\"]].groupby(\"marker\")[\"total\"].sum().rename(\"clean_marker_total_wo_OS_THR\")\n",
    "    df = df.merge(clean_total_per_marker, on=\"marker\", how=\"left\")\n",
    "\n",
    "    # Step 3: Compute normalized variant frequency (only for retained rows)\n",
    "    df[\"variant_frequency_wo_OS_THR\"] = (df[\"total\"] / df[\"clean_marker_total_wo_OS_THR\"] * 100).round(2)\n",
    "\n",
    "    # Step 5: Split multiple variants\n",
    "    df = df.assign(sequence=df[\"sequence\"].str.split())\n",
    "    df = df.explode(\"sequence\").reset_index(drop=True)\n",
    "    \n",
    "    # Step 4: Flag rows to retain\n",
    "    drop_seqs = [\"Other\", \"sequences\", \"REF\", \"N3107DEL\"]\n",
    "    df = df[(~df[\"sequence\"].isin(drop_seqs)) & (df[\"total_mp_sum\"] >= threshold)].copy()\n",
    "\n",
    "\n",
    "    # Step 6: Calculate estimated coverage for each row\n",
    "    df[\"estimated_total_coverage\"] = (\n",
    "        df[\"total\"] / (df[\"total_mp_sum\"] / 100)\n",
    "    ).round(0).astype(\"Int64\")\n",
    "\n",
    "\n",
    "    # Step 7: Group by marker + sequence to sum within same marker\n",
    "    grouped_same_marker = df.groupby([\"marker\", \"sequence\"], as_index=False).agg(\n",
    "        # total=(\"total\", \"sum\"),\n",
    "        # total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        # estimated_total_coverage=(\"estimated_total_coverage\", \"sum\")\n",
    "        total=(\"total\", \"sum\"),\n",
    "        total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        estimated_total_coverage=(\"estimated_total_coverage\", \"max\"),\n",
    "        is_noise_or_low=(\"is_noise_or_low\", \"first\"),\n",
    "        clean_marker_total_wo_OS_THR=(\"clean_marker_total_wo_OS_THR\", \"first\"),\n",
    "        variant_frequency_wo_OS_THR=(\"variant_frequency_wo_OS_THR\", \"sum\")\n",
    "    )\n",
    "    # # print(grouped_same_marker)\n",
    "    # # Step 8: Recompute variant_frequency within marker\n",
    "    # grouped_same_marker[\"variant_frequency\"] = (\n",
    "    #     grouped_same_marker[\"total\"] / grouped_same_marker[\"estimated_total_coverage\"] * 100\n",
    "    # ).round(1)\n",
    "\n",
    "    # print(grouped_same_marker)\n",
    "    \n",
    "    # Step 9: Group across markers to merge overlapping amplicons (same variant)\n",
    "    # df[\"estimated_total_coverage_across_markers\"] = (df[\"total\"] / (df[\"total_mp_sum\"] / 100)).round(0).astype(\"Int64\")\n",
    "    grouped_final = grouped_same_marker.groupby(\"sequence\", as_index=False).agg(\n",
    "        total=(\"total\", \"sum\"),\n",
    "        # total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        estimated_total_coverage=(\"estimated_total_coverage\", \"sum\"),\n",
    "        # estimated_total_coverage_across_markers=(\"estimated_total_coverage_across_markers\", \"sum\"),\n",
    "        is_noise_or_low=(\"is_noise_or_low\", \"first\"),\n",
    "        clean_marker_total_wo_OS_THR=(\"clean_marker_total_wo_OS_THR\", \"sum\"),\n",
    "        # variant_frequency_wo_OS_THR=(\"variant_frequency_wo_OS_THR\", \"sum\"),\n",
    "        num_markers=(\"marker\", \"nunique\")\n",
    "    )\n",
    "\n",
    "\n",
    "    # print(grouped_final)\n",
    "    \n",
    "    grouped_final[\"variant_frequency\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"estimated_total_coverage\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    grouped_final[\"variant_frequency_wo_OS_THR\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"clean_marker_total_wo_OS_THR\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"sequence\"].apply(extract_position)\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    \n",
    "    # Step 11: Apply IUPAC codes for heteroplasmies\n",
    "    # Step 11: Apply IUPAC codes and adjust formatting for heteroplasmies\n",
    "    def resolve_heteroplasmy(row):\n",
    "        seq = row['sequence']\n",
    "    \n",
    "        # Handle deletions\n",
    "        if 'DEL' in seq:\n",
    "            return seq.replace('DEL', '-')\n",
    "\n",
    "        # Handle insertions: prefix with \"-\"\n",
    "\n",
    "        # Handle insertions / length heteroplasmies\n",
    "        if '.' in seq:\n",
    "            if row['variant_frequency_wo_OS_THR'] < 92:\n",
    "                return '-' + seq[:-1] + seq[-1].lower()  # e.g. 309.2C -> 309.2c\n",
    "            else:\n",
    "                return '-' + seq # leave as-is if frequency is high\n",
    "\n",
    "       \n",
    "        \n",
    "        # Handle point heteroplasmies with IUPAC\n",
    "        if row['variant_frequency_wo_OS_THR'] < 92:\n",
    "            match = re.match(r'([ACGT])(\\d+)([ACGT])', seq)\n",
    "            if not match:\n",
    "                return seq\n",
    "            ref, pos, alt = match.groups()\n",
    "            code = IUPAC_CODES.get(frozenset([ref, alt]))\n",
    "            if code:\n",
    "                return f\"{ref}{pos}{code}\"\n",
    "    \n",
    "        return seq\n",
    "\n",
    "\n",
    "\n",
    "    grouped_final['sequence'] = grouped_final.apply(resolve_heteroplasmy, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    print(grouped_final)\n",
    "    \n",
    "    return grouped_final\n",
    "    # return grouped_final, df\n",
    "\n",
    "# # Placeholder path \n",
    "tsv_path = \"s23-11303-E1_S13_L001.sast.csv\"\n",
    "reference_sequence = \"../rCRS/rCRS2.fasta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7bdc3b07-c7c6-4d39-8fd8-99f497e091c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sequence  total  estimated_total_coverage  is_noise_or_low  \\\n",
      "18    T152C   1907                      1967            False   \n",
      "5     A263G   1605                      1726            False   \n",
      "0    309.1C    475                       554            False   \n",
      "1    309.2c     64                       552            False   \n",
      "2    315.1C    475                       554            False   \n",
      "13    C456T   1560                      1761            False   \n",
      "8     A523-   1560                      1761            False   \n",
      "14    C524-   1560                      1761            False   \n",
      "21    T710C   3520                      3737            False   \n",
      "10    A750G   3520                      3737            False   \n",
      "3    A1438G   2565                      2764            False   \n",
      "6    A3447M     35                       245            False   \n",
      "20   T4336C   3464                      3729            False   \n",
      "7    A4769G   1102                      1224            False   \n",
      "9    A6419M    215                      2181            False   \n",
      "15   C7469Y    915                      3315            False   \n",
      "11   A8860G   1476                      1618            False   \n",
      "16  G10310A   2049                      2189            False   \n",
      "17  T14422Y    203                      1390            False   \n",
      "4   A15326G   2452                      2642            False   \n",
      "12  C15833T   2229                      2336            False   \n",
      "19  T16304C   2800                      2988            False   \n",
      "\n",
      "    clean_marker_total_wo_OS_THR  num_markers  variant_frequency  \\\n",
      "18                          1907            2               96.9   \n",
      "5                           1605            2               93.0   \n",
      "0                            475            1               85.7   \n",
      "1                            475            1               11.6   \n",
      "2                            475            1               85.7   \n",
      "13                          1560            1               88.6   \n",
      "8                           1560            1               88.6   \n",
      "14                          1560            1               88.6   \n",
      "21                          3520            1               94.2   \n",
      "10                          3520            1               94.2   \n",
      "3                           2565            2               92.8   \n",
      "6                             73            1               14.3   \n",
      "20                          3464            1               92.9   \n",
      "7                           1102            1               90.0   \n",
      "9                           2012            1                9.9   \n",
      "15                          3070            1               27.6   \n",
      "11                          1476            1               91.2   \n",
      "16                          2049            1               93.6   \n",
      "17                          1287            1               14.6   \n",
      "4                           2452            1               92.8   \n",
      "12                          2229            1               95.4   \n",
      "19                          2800            1               93.7   \n",
      "\n",
      "    variant_frequency_wo_OS_THR  \n",
      "18                        100.0  \n",
      "5                         100.0  \n",
      "0                         100.0  \n",
      "1                          13.5  \n",
      "2                         100.0  \n",
      "13                        100.0  \n",
      "8                         100.0  \n",
      "14                        100.0  \n",
      "21                        100.0  \n",
      "10                        100.0  \n",
      "3                         100.0  \n",
      "6                          47.9  \n",
      "20                        100.0  \n",
      "7                         100.0  \n",
      "9                          10.7  \n",
      "15                         29.8  \n",
      "11                        100.0  \n",
      "16                        100.0  \n",
      "17                         15.8  \n",
      "4                         100.0  \n",
      "12                        100.0  \n",
      "19                        100.0  \n"
     ]
    }
   ],
   "source": [
    "processed_df = process_fdstools_sast(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8182ec-9d6b-4f0d-b830-4fe3593c2cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "26acfdb6-5ab7-4b40-8705-0805a718664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"s23-11303-E1_S13_L001_processed10.txt\" \n",
    "processed_df.to_csv(output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2980e6-7cf1-4f9c-bf97-d0aa67debcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5888a8a7-917d-4624-9c79-df85c494882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def process_empop_variant_table(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a variant table with EMPOP-style variant annotations.\n",
    "    - Splits multi-variant rows\n",
    "    - Sums VariantLevel and allele-specific Coverage\n",
    "    - Keeps the first value of MeanBaseQuality\n",
    "    - Sorts variants by position\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: path to the tab-separated file\n",
    "\n",
    "    Returns:\n",
    "    - A cleaned and sorted DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Load file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    # Split EMPOP_Variant column and explode into rows\n",
    "    df[\"EMPOP_Variant\"] = df[\"EMPOP_Variant\"].astype(str).str.split()\n",
    "    df = df.explode(\"EMPOP_Variant\").reset_index(drop=True)\n",
    "\n",
    "    # Convert numeric columns\n",
    "    df[\"VariantLevel\"] = pd.to_numeric(df[\"VariantLevel\"], errors=\"coerce\")\n",
    "\n",
    "    # Helper: sum comma-separated numbers elementwise\n",
    "    def add_comma_separated_numbers(series):\n",
    "        split_lists = series.dropna().astype(str).apply(lambda x: list(map(float, x.split(','))))\n",
    "        if split_lists.empty:\n",
    "            return \"\"\n",
    "        summed = [sum(x) for x in zip(*split_lists)]\n",
    "        return \",\".join(f\"{s:.4g}\" for s in summed)\n",
    "\n",
    "    # Aggregate\n",
    "    group_keys = [\"EMPOP_Variant\"]\n",
    "    numeric_agg = {\n",
    "        \"VariantLevel\": \"sum\",\n",
    "        \"Coverage\": add_comma_separated_numbers,\n",
    "        \"MeanBaseQuality\": \"first\"\n",
    "    }\n",
    "    other_cols = [col for col in df.columns if col not in numeric_agg and col not in group_keys]\n",
    "    full_agg = {**numeric_agg, **{col: \"first\" for col in other_cols}}\n",
    "\n",
    "    grouped = df.groupby(group_keys, as_index=False).agg(full_agg)\n",
    "\n",
    "    # Sort by numeric position extracted from variant\n",
    "    def extract_position(variant):\n",
    "        match = re.search(r\"(\\d+\\.?\\d*)\", str(variant))\n",
    "        return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "    grouped[\"position\"] = grouped[\"EMPOP_Variant\"].apply(extract_position)\n",
    "    grouped = grouped.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    def correct_length_het_case(row):\n",
    "        if \".\" in row[\"EMPOP_Variant\"] and row[\"VariantLevel\"] >= 0.92:\n",
    "            return row[\"EMPOP_Variant\"][:-1] + row[\"EMPOP_Variant\"][-1].upper()\n",
    "        return row[\"EMPOP_Variant\"]\n",
    "\n",
    "    grouped[\"EMPOP_Variant\"] = grouped.apply(correct_length_het_case, axis=1)\n",
    "    \n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ceafbc3a-056a-4ff3-9630-2023599d465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop.txt\"\n",
    "grouped_variants = process_empop_variant_table(input_path)\n",
    "\n",
    "# Save results\n",
    "grouped_variants.to_csv(\"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop_grouped.txt\", sep=\"\\t\", index=False)\n",
    "# exploded_df.to_csv(\"exploded_variants.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ead507-3231-44e9-9958-d9b5ea95c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned = process_empop_variant_table(\"your_input_file.tsv\")\n",
    "# df_cleaned.to_csv(\"cleaned_empop_variants.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0e857020-4262-408c-a6c4-38158868ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def merge_variant_callers(file1: str, file2: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges two variant tables from different callers on their variant column.\n",
    "    \n",
    "    Parameters:\n",
    "        file1: Path to the first variant caller table (expects 'sequence' column)\n",
    "        file2: Path to the second variant caller table (expects 'EMPOP_Variant' column)\n",
    "        \n",
    "    Returns:\n",
    "        A merged DataFrame with flags and full column preservation, sorted by position.\n",
    "    \"\"\"\n",
    "    # Load both files\n",
    "    df1 = pd.read_csv(file1, sep=\"\\t\")\n",
    "    df2 = pd.read_csv(file2, sep=\"\\t\")\n",
    "    \n",
    "    # Rename variant columns to common key\n",
    "    df1 = df1.rename(columns={\"sequence\": \"variant\"})\n",
    "    df2 = df2.rename(columns={\"EMPOP_Variant\": \"variant\"})\n",
    "    \n",
    "    # Merge the dataframes on the variant column\n",
    "    merged = pd.merge(df1, df2, on=\"variant\", how=\"outer\", suffixes=(\"_vc1\", \"_vc2\"))\n",
    "\n",
    "    # Add flags for presence in each caller\n",
    "    merged[\"called_in_vc1\"] = ~merged[\"total\"].isna()\n",
    "    merged[\"called_in_vc2\"] = ~merged[\"VariantLevel\"].isna()\n",
    "\n",
    "    # Extract numeric position for sorting\n",
    "    def extract_position(seq):\n",
    "        match = re.search(r\"(\\d+\\.?\\d*)\", str(seq))\n",
    "        return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "    merged[\"variant_position\"] = merged[\"variant\"].apply(extract_position)\n",
    "    merged = merged.sort_values(by=\"variant_position\").drop(columns=[\"variant_position\"])\n",
    "\n",
    "    # Reorder columns for clarity\n",
    "    front = [\"variant\", \"called_in_vc1\", \"called_in_vc2\"]\n",
    "    other = [col for col in merged.columns if col not in front]\n",
    "    merged = merged[front + other]\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4acd3a2d-f8c8-498c-9ad8-7742f5e4dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_variant_callers(\"s23-11303-E1_S13_L001_processed10.txt\",\"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop_grouped.txt\")\n",
    "df_merged.to_csv(\"merged_variants2.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5529b-129d-4f2e-9171-66cd7ddd067a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
