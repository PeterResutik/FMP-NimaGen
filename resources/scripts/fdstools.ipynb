{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222e67c-151b-4ad5-8852-98a705f2587b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d753ada-4402-4411-b20f-44da4deeae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8d318-e797-4743-812e-cd5533ddf445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed278574-11e0-463b-a102-a1576d778a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdbb55-7981-4953-91b1-e8e57744e255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf24e84-4d95-4125-8e6f-7dee9e2ece49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652b9c2d-79d4-4d76-aac1-e26d6439b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 10: Extract numeric positions from the sequence column for sorting\n",
    "def extract_position(seq):\n",
    "    match = re.search(r\"(\\d+\\.?\\d*)\", seq)\n",
    "    return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Define function to process FDSTools SAST TSV files\n",
    "def process_fdstools_sast(file_path: str, threshold: float = 8.0):\n",
    "    IUPAC_CODES = {\n",
    "        frozenset([\"A\", \"G\"]): \"R\",\n",
    "        frozenset([\"C\", \"T\"]): \"Y\",\n",
    "        frozenset([\"A\", \"C\"]): \"M\",\n",
    "        frozenset([\"G\", \"T\"]): \"K\",\n",
    "        frozenset([\"G\", \"C\"]): \"S\",\n",
    "        frozenset([\"A\", \"T\"]): \"W\"\n",
    "    }\n",
    "\n",
    "    # Load the FDSTools SAST TSV file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "    # Convert total_mp_sum and total to numeric types\n",
    "    df[\"total_mp_sum\"] = pd.to_numeric(df[\"total_mp_sum\"], errors=\"coerce\")\n",
    "    df[\"total\"] = pd.to_numeric(df[\"total\"], errors=\"coerce\")\n",
    "\n",
    "    # Count each target (e.g. mtNG_004) and flag those with a single occurrence and low total\n",
    "    marker_counts = df[\"marker\"].value_counts()\n",
    "    single_low_coverage = df[df[\"marker\"].isin(marker_counts[marker_counts == 1].index) & (df[\"total\"] < 10)].copy()\n",
    "\n",
    "    # if not single_low_coverage.empty:\n",
    "    #     print(\"Markers with single entries and total < 10:\")\n",
    "    #     print(single_low_coverage[[\"marker\", \"sequence\", \"total\"]])\n",
    "\n",
    "    # Replace 'sequence' column with 'marker' for low-coverage targets\n",
    "    single_low_coverage[\"sequence\"] = single_low_coverage[\"marker\"]\n",
    "    single_low_coverage = single_low_coverage.drop(columns=[\"marker\"])\n",
    "    \n",
    "    # Optional: Write to CSV for external review\n",
    "    # single_low_coverage.to_csv(\"low_coverage_singleton_segments.csv\", index=False)\n",
    "\n",
    "    \n",
    "    # Step 1: Fill NaN in total and total_mp_sum with zeros\n",
    "    df[\"total\"] = df[\"total\"].fillna(0)\n",
    "    df[\"total_mp_sum\"] = df[\"total_mp_sum\"].fillna(0)\n",
    "\n",
    "    # Step 2: Flag rows with total read depth lower than threshold and low-confidence sequences\n",
    "    df[\"is_noise_or_low\"] = (df[\"sequence\"].isin([\"Other sequences\"])) | (df[\"total_mp_sum\"] < threshold)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "    \"total_mp_max\", \"forward_pct\", \"forward\", \"forward_mp_sum\",\n",
    "    \"forward_mp_max\", \"reverse\", \"reverse_mp_sum\", \"reverse_mp_max\"]\n",
    "    \n",
    "    df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "    # Merge clean_marker_total_wo_OS_THR back into the main DataFrame.\n",
    "    clean_total_per_marker = df[~df[\"is_noise_or_low\"]].groupby(\"marker\")[\"total\"].sum().rename(\"clean_marker_total_wo_OS_THR\")\n",
    "    df = df.merge(clean_total_per_marker, on=\"marker\", how=\"left\")\n",
    "\n",
    "    # Step 3: Compute normalized variant frequency (only for retained rows)\n",
    "    df[\"variant_frequency_wo_OS_THR\"] = (df[\"total\"] / df[\"clean_marker_total_wo_OS_THR\"] * 100).round(2)\n",
    "\n",
    "    # Step 5: Split multiple variants\n",
    "    df = df.assign(sequence=df[\"sequence\"].str.split())\n",
    "    df = df.explode(\"sequence\").reset_index(drop=True)\n",
    "    \n",
    "    # Step 4: Flag rows to drop\n",
    "    drop_seqs = [\"Other\", \"sequences\", \"REF\", \"N3107DEL\"]\n",
    "    df = df[(~df[\"sequence\"].isin(drop_seqs)) & (df[\"total_mp_sum\"] >= threshold)].copy()\n",
    "\n",
    "    # Step 6: Calculate estimated coverage for each row\n",
    "    df[\"estimated_total_coverage\"] = (\n",
    "        df[\"total\"] / (df[\"total_mp_sum\"] / 100)\n",
    "    ).round(0).astype(\"Int64\")\n",
    "\n",
    "    # Step 7: Group by marker + sequence to sum within same marker\n",
    "    grouped_same_marker = df.groupby([\"marker\", \"sequence\"], as_index=False).agg(\n",
    "        # total=(\"total\", \"sum\"),\n",
    "        # total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        # estimated_total_coverage=(\"estimated_total_coverage\", \"sum\")\n",
    "        total=(\"total\", \"sum\"),\n",
    "        total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        estimated_total_coverage=(\"estimated_total_coverage\", \"max\"),\n",
    "        is_noise_or_low=(\"is_noise_or_low\", \"first\"),\n",
    "        clean_marker_total_wo_OS_THR=(\"clean_marker_total_wo_OS_THR\", \"first\"),\n",
    "        variant_frequency_wo_OS_THR=(\"variant_frequency_wo_OS_THR\", \"sum\")\n",
    "    )\n",
    "    # # print(grouped_same_marker)\n",
    "    # # Step 8: Recompute variant_frequency within marker\n",
    "    # grouped_same_marker[\"variant_frequency\"] = (\n",
    "    #     grouped_same_marker[\"total\"] / grouped_same_marker[\"estimated_total_coverage\"] * 100\n",
    "    # ).round(1)\n",
    "\n",
    "    # print(grouped_same_marker)\n",
    "    \n",
    "    # Step 9: Group across markers to merge overlapping amplicons (same variant)\n",
    "    # df[\"estimated_total_coverage_across_markers\"] = (df[\"total\"] / (df[\"total_mp_sum\"] / 100)).round(0).astype(\"Int64\")\n",
    "    grouped_final = grouped_same_marker.groupby(\"sequence\", as_index=False).agg(\n",
    "        total=(\"total\", \"sum\"),\n",
    "        # total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        estimated_total_coverage=(\"estimated_total_coverage\", \"sum\"),\n",
    "        # estimated_total_coverage_across_markers=(\"estimated_total_coverage_across_markers\", \"sum\"),\n",
    "        is_noise_or_low=(\"is_noise_or_low\", \"first\"),\n",
    "        clean_marker_total_wo_OS_THR=(\"clean_marker_total_wo_OS_THR\", \"sum\"),\n",
    "        # variant_frequency_wo_OS_THR=(\"variant_frequency_wo_OS_THR\", \"sum\"),\n",
    "        num_markers=(\"marker\", \"nunique\")\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # print(grouped_final)\n",
    "    \n",
    "    grouped_final[\"variant_frequency\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"estimated_total_coverage\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    grouped_final[\"variant_frequency_wo_OS_THR\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"clean_marker_total_wo_OS_THR\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"sequence\"].apply(extract_position)\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    \n",
    "    # Step 11: Apply IUPAC codes for heteroplasmies\n",
    "    # Step 11: Apply IUPAC codes and adjust formatting for heteroplasmies\n",
    "    def resolve_heteroplasmy(row):\n",
    "        seq = row['sequence']\n",
    "    \n",
    "        # Handle deletions\n",
    "        if 'DEL' in seq:\n",
    "            return seq.replace('DEL', '-')\n",
    "\n",
    "        # Handle insertions: prefix with \"-\"\n",
    "\n",
    "        # Handle insertions / length heteroplasmies\n",
    "        if '.' in seq:\n",
    "            if row['variant_frequency_wo_OS_THR'] < 92:\n",
    "                return '-' + seq[:-1] + seq[-1].lower()  # e.g. 309.2C -> 309.2c\n",
    "            else:\n",
    "                return '-' + seq # leave as-is if frequency is high\n",
    "\n",
    "        # Handle point heteroplasmies with IUPAC\n",
    "        if row['variant_frequency_wo_OS_THR'] < 92:\n",
    "            match = re.match(r'([ACGT])(\\d+)([ACGT])', seq)\n",
    "            if not match:\n",
    "                return seq\n",
    "            ref, pos, alt = match.groups()\n",
    "            code = IUPAC_CODES.get(frozenset([ref, alt]))\n",
    "            if code:\n",
    "                return f\"{ref}{pos}{code}\"\n",
    "    \n",
    "        return seq\n",
    "\n",
    "\n",
    "\n",
    "    grouped_final['sequence'] = grouped_final.apply(resolve_heteroplasmy, axis=1)\n",
    "\n",
    "    grouped_final = pd.concat([grouped_final, single_low_coverage], ignore_index=False)\n",
    "\n",
    "    print(grouped_final)\n",
    "    \n",
    "    return grouped_final\n",
    "    # return grouped_final, df\n",
    "\n",
    "# # Placeholder path \n",
    "tsv_path = \"s23-11298-E1_S16_L001.sast.csv\"\n",
    "reference_sequence = \"../rCRS/rCRS2.fasta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bdc3b07-c7c6-4d39-8fd8-99f497e091c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markers with single entries and total < 10:\n",
      "       marker sequence  total\n",
      "499  mtNG_099  No data      0\n",
      "      sequence  total  estimated_total_coverage is_noise_or_low  \\\n",
      "7        A263G   1853                      2037           False   \n",
      "1      -309.1C    469                       588           False   \n",
      "2      -309.2c    114                       588           False   \n",
      "3      -315.1C    469                       588           False   \n",
      "11       A523-   1478                      1802           False   \n",
      "16       C524-   1478                      1802           False   \n",
      "13       A750G   2298                      2479           False   \n",
      "4       A1438G   1887                      2026           False   \n",
      "18      G3010A   2049                      2173           False   \n",
      "8       A3447M     28                       172           False   \n",
      "9       A3796G   3294                      3504           False   \n",
      "10      A4769G    927                       998           False   \n",
      "12      A6419M    192                      2015           False   \n",
      "14      A8860G   1472                      1643           False   \n",
      "5      A15326G   1917                      2137           False   \n",
      "17     G16129A    230                       291           False   \n",
      "6      A16183C    230                       291           False   \n",
      "19     T16189Y    198                       290           False   \n",
      "20     T16189-     32                       291           False   \n",
      "0    -16193.1c     95                       290           False   \n",
      "15     C16355T    639                       686           False   \n",
      "21     T16356C    639                       686           False   \n",
      "22     T16362C    639                       686           False   \n",
      "23     T16519C   1738                      1824           False   \n",
      "499   mtNG_099      0                      <NA>             NaN   \n",
      "\n",
      "     clean_marker_total_wo_OS_THR  num_markers  variant_frequency  \\\n",
      "7                          1853.0          2.0               91.0   \n",
      "1                           469.0          1.0               79.8   \n",
      "2                           469.0          1.0               19.4   \n",
      "3                           469.0          1.0               79.8   \n",
      "11                         1478.0          1.0               82.0   \n",
      "16                         1478.0          1.0               82.0   \n",
      "13                         2298.0          1.0               92.7   \n",
      "4                          1887.0          2.0               93.1   \n",
      "18                         2049.0          1.0               94.3   \n",
      "8                            49.0          1.0               16.3   \n",
      "9                          3294.0          1.0               94.0   \n",
      "10                          927.0          1.0               92.9   \n",
      "12                         1850.0          1.0                9.5   \n",
      "14                         1472.0          1.0               89.6   \n",
      "5                          1917.0          1.0               89.7   \n",
      "17                          230.0          1.0               79.0   \n",
      "6                           230.0          1.0               79.0   \n",
      "19                          230.0          1.0               68.3   \n",
      "20                          230.0          1.0               11.0   \n",
      "0                           230.0          1.0               32.8   \n",
      "15                          639.0          1.0               93.1   \n",
      "21                          639.0          1.0               93.1   \n",
      "22                          639.0          1.0               93.1   \n",
      "23                         1738.0          1.0               95.3   \n",
      "499                           NaN          NaN               <NA>   \n",
      "\n",
      "     variant_frequency_wo_OS_THR flags  total_mp_sum total_mp_max forward_pct  \\\n",
      "7                          100.0   NaN           NaN          NaN         NaN   \n",
      "1                          100.0   NaN           NaN          NaN         NaN   \n",
      "2                           24.3   NaN           NaN          NaN         NaN   \n",
      "3                          100.0   NaN           NaN          NaN         NaN   \n",
      "11                         100.0   NaN           NaN          NaN         NaN   \n",
      "16                         100.0   NaN           NaN          NaN         NaN   \n",
      "13                         100.0   NaN           NaN          NaN         NaN   \n",
      "4                          100.0   NaN           NaN          NaN         NaN   \n",
      "18                         100.0   NaN           NaN          NaN         NaN   \n",
      "8                           57.1   NaN           NaN          NaN         NaN   \n",
      "9                          100.0   NaN           NaN          NaN         NaN   \n",
      "10                         100.0   NaN           NaN          NaN         NaN   \n",
      "12                          10.4   NaN           NaN          NaN         NaN   \n",
      "14                         100.0   NaN           NaN          NaN         NaN   \n",
      "5                          100.0   NaN           NaN          NaN         NaN   \n",
      "17                         100.0   NaN           NaN          NaN         NaN   \n",
      "6                          100.0   NaN           NaN          NaN         NaN   \n",
      "19                          86.1   NaN           NaN          NaN         NaN   \n",
      "20                          13.9   NaN           NaN          NaN         NaN   \n",
      "0                           41.3   NaN           NaN          NaN         NaN   \n",
      "15                         100.0   NaN           NaN          NaN         NaN   \n",
      "21                         100.0   NaN           NaN          NaN         NaN   \n",
      "22                         100.0   NaN           NaN          NaN         NaN   \n",
      "23                         100.0   NaN           NaN          NaN         NaN   \n",
      "499                          NaN   NaN           0.0         0.00        0.00   \n",
      "\n",
      "    forward forward_mp_sum forward_mp_max reverse reverse_mp_sum  \\\n",
      "7       NaN            NaN            NaN     NaN            NaN   \n",
      "1       NaN            NaN            NaN     NaN            NaN   \n",
      "2       NaN            NaN            NaN     NaN            NaN   \n",
      "3       NaN            NaN            NaN     NaN            NaN   \n",
      "11      NaN            NaN            NaN     NaN            NaN   \n",
      "16      NaN            NaN            NaN     NaN            NaN   \n",
      "13      NaN            NaN            NaN     NaN            NaN   \n",
      "4       NaN            NaN            NaN     NaN            NaN   \n",
      "18      NaN            NaN            NaN     NaN            NaN   \n",
      "8       NaN            NaN            NaN     NaN            NaN   \n",
      "9       NaN            NaN            NaN     NaN            NaN   \n",
      "10      NaN            NaN            NaN     NaN            NaN   \n",
      "12      NaN            NaN            NaN     NaN            NaN   \n",
      "14      NaN            NaN            NaN     NaN            NaN   \n",
      "5       NaN            NaN            NaN     NaN            NaN   \n",
      "17      NaN            NaN            NaN     NaN            NaN   \n",
      "6       NaN            NaN            NaN     NaN            NaN   \n",
      "19      NaN            NaN            NaN     NaN            NaN   \n",
      "20      NaN            NaN            NaN     NaN            NaN   \n",
      "0       NaN            NaN            NaN     NaN            NaN   \n",
      "15      NaN            NaN            NaN     NaN            NaN   \n",
      "21      NaN            NaN            NaN     NaN            NaN   \n",
      "22      NaN            NaN            NaN     NaN            NaN   \n",
      "23      NaN            NaN            NaN     NaN            NaN   \n",
      "499       0           0.00           0.00       0           0.00   \n",
      "\n",
      "    reverse_mp_max  \n",
      "7              NaN  \n",
      "1              NaN  \n",
      "2              NaN  \n",
      "3              NaN  \n",
      "11             NaN  \n",
      "16             NaN  \n",
      "13             NaN  \n",
      "4              NaN  \n",
      "18             NaN  \n",
      "8              NaN  \n",
      "9              NaN  \n",
      "10             NaN  \n",
      "12             NaN  \n",
      "14             NaN  \n",
      "5              NaN  \n",
      "17             NaN  \n",
      "6              NaN  \n",
      "19             NaN  \n",
      "20             NaN  \n",
      "0              NaN  \n",
      "15             NaN  \n",
      "21             NaN  \n",
      "22             NaN  \n",
      "23             NaN  \n",
      "499           0.00  \n"
     ]
    }
   ],
   "source": [
    "processed_df = process_fdstools_sast(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8182ec-9d6b-4f0d-b830-4fe3593c2cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "26acfdb6-5ab7-4b40-8705-0805a718664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"s23-11303-E1_S13_L001_processed10.txt\" \n",
    "processed_df.to_csv(output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2980e6-7cf1-4f9c-bf97-d0aa67debcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5888a8a7-917d-4624-9c79-df85c494882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def process_empop_variant_table(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a variant table with EMPOP-style variant annotations.\n",
    "    - Splits multi-variant rows\n",
    "    - Sums VariantLevel and allele-specific Coverage\n",
    "    - Keeps the first value of MeanBaseQuality\n",
    "    - Sorts variants by position\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: path to the tab-separated file\n",
    "\n",
    "    Returns:\n",
    "    - A cleaned and sorted DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Load file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    # Split EMPOP_Variant column and explode into rows\n",
    "    df[\"EMPOP_Variant\"] = df[\"EMPOP_Variant\"].astype(str).str.split()\n",
    "    df = df.explode(\"EMPOP_Variant\").reset_index(drop=True)\n",
    "\n",
    "    # Convert numeric columns\n",
    "    df[\"VariantLevel\"] = pd.to_numeric(df[\"VariantLevel\"], errors=\"coerce\")\n",
    "\n",
    "    # Helper: sum comma-separated numbers elementwise\n",
    "    def add_comma_separated_numbers(series):\n",
    "        split_lists = series.dropna().astype(str).apply(lambda x: list(map(float, x.split(','))))\n",
    "        if split_lists.empty:\n",
    "            return \"\"\n",
    "        summed = [sum(x) for x in zip(*split_lists)]\n",
    "        return \",\".join(f\"{s:.4g}\" for s in summed)\n",
    "\n",
    "    # Aggregate\n",
    "    group_keys = [\"EMPOP_Variant\"]\n",
    "    numeric_agg = {\n",
    "        \"VariantLevel\": \"sum\",\n",
    "        \"Coverage\": add_comma_separated_numbers,\n",
    "        \"MeanBaseQuality\": \"first\"\n",
    "    }\n",
    "    other_cols = [col for col in df.columns if col not in numeric_agg and col not in group_keys]\n",
    "    full_agg = {**numeric_agg, **{col: \"first\" for col in other_cols}}\n",
    "\n",
    "    grouped = df.groupby(group_keys, as_index=False).agg(full_agg)\n",
    "\n",
    "    # Sort by numeric position extracted from variant\n",
    "    def extract_position(variant):\n",
    "        match = re.search(r\"(\\d+\\.?\\d*)\", str(variant))\n",
    "        return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "    grouped[\"position\"] = grouped[\"EMPOP_Variant\"].apply(extract_position)\n",
    "    grouped = grouped.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    def correct_length_het_case(row):\n",
    "        if \".\" in row[\"EMPOP_Variant\"] and row[\"VariantLevel\"] >= 0.92:\n",
    "            return row[\"EMPOP_Variant\"][:-1] + row[\"EMPOP_Variant\"][-1].upper()\n",
    "        return row[\"EMPOP_Variant\"]\n",
    "\n",
    "    grouped[\"EMPOP_Variant\"] = grouped.apply(correct_length_het_case, axis=1)\n",
    "    \n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ceafbc3a-056a-4ff3-9630-2023599d465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop.txt\"\n",
    "grouped_variants = process_empop_variant_table(input_path)\n",
    "\n",
    "# Save results\n",
    "grouped_variants.to_csv(\"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop_grouped.txt\", sep=\"\\t\", index=False)\n",
    "# exploded_df.to_csv(\"exploded_variants.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ead507-3231-44e9-9958-d9b5ea95c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned = process_empop_variant_table(\"your_input_file.tsv\")\n",
    "# df_cleaned.to_csv(\"cleaned_empop_variants.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0e857020-4262-408c-a6c4-38158868ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def merge_variant_callers(file1: str, file2: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges two variant tables from different callers on their variant column.\n",
    "    \n",
    "    Parameters:\n",
    "        file1: Path to the first variant caller table (expects 'sequence' column)\n",
    "        file2: Path to the second variant caller table (expects 'EMPOP_Variant' column)\n",
    "        \n",
    "    Returns:\n",
    "        A merged DataFrame with flags and full column preservation, sorted by position.\n",
    "    \"\"\"\n",
    "    # Load both files\n",
    "    df1 = pd.read_csv(file1, sep=\"\\t\")\n",
    "    df2 = pd.read_csv(file2, sep=\"\\t\")\n",
    "    \n",
    "    # Rename variant columns to common key\n",
    "    df1 = df1.rename(columns={\"sequence\": \"variant\"})\n",
    "    df2 = df2.rename(columns={\"EMPOP_Variant\": \"variant\"})\n",
    "    \n",
    "    # Merge the dataframes on the variant column\n",
    "    merged = pd.merge(df1, df2, on=\"variant\", how=\"outer\", suffixes=(\"_vc1\", \"_vc2\"))\n",
    "\n",
    "    # Add flags for presence in each caller\n",
    "    merged[\"called_in_vc1\"] = ~merged[\"total\"].isna()\n",
    "    merged[\"called_in_vc2\"] = ~merged[\"VariantLevel\"].isna()\n",
    "\n",
    "    # Extract numeric position for sorting\n",
    "    def extract_position(seq):\n",
    "        match = re.search(r\"(\\d+\\.?\\d*)\", str(seq))\n",
    "        return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "    merged[\"variant_position\"] = merged[\"variant\"].apply(extract_position)\n",
    "    merged = merged.sort_values(by=\"variant_position\").drop(columns=[\"variant_position\"])\n",
    "\n",
    "    # Reorder columns for clarity\n",
    "    front = [\"variant\", \"called_in_vc1\", \"called_in_vc2\"]\n",
    "    other = [col for col in merged.columns if col not in front]\n",
    "    merged = merged[front + other]\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4acd3a2d-f8c8-498c-9ad8-7742f5e4dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_variant_callers(\"s23-11303-E1_S13_L001_processed10.txt\",\"s23-11303-E1_S13_L001.rtn.vcf.mutect2_fusion.filtered.empop_grouped.txt\")\n",
    "df_merged.to_csv(\"merged_variants2.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "84e5529b-129d-4f2e-9171-66cd7ddd067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Step 10: Extract numeric positions from the sequence column for sorting\n",
    "def extract_position(seq):\n",
    "    match = re.search(r\"(\\d+\\.?\\d*)\", seq)\n",
    "    return float(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Step 11: Apply IUPAC codes and adjust formatting for heteroplasmies\n",
    "def resolve_heteroplasmy(row, min_variant_frequency_pct, length_heteroplasmy_threshold, IUPAC_CODES):\n",
    "    seq = row['sequence']\n",
    "\n",
    "    # Handle deletions\n",
    "    if 'DEL' in seq:\n",
    "        return seq.replace('DEL', '-')\n",
    "\n",
    "    # Handle insertions / length heteroplasmies\n",
    "    if '.' in seq:\n",
    "        if row['variant_frequency_wo_noise_or_low_frq'] < length_heteroplasmy_threshold:\n",
    "            return '-' + seq[:-1] + seq[-1].lower()  # e.g. 309.2C -> 309.2c\n",
    "        else:\n",
    "            return '-' + seq # leave as-is if frequency is high\n",
    "\n",
    "    # Handle point heteroplasmies with IUPAC\n",
    "    if row['variant_frequency_wo_noise_or_low_frq'] < 100-min_variant_frequency_pct:\n",
    "        match = re.match(r'([ACGT])(\\d+)([ACGT])', seq)\n",
    "        if not match:\n",
    "            return seq\n",
    "        ref, pos, alt = match.groups()\n",
    "        code = IUPAC_CODES.get(frozenset([ref, alt]))\n",
    "        if code:\n",
    "            return f\"{ref}{pos}{code}\"\n",
    "\n",
    "    return seq\n",
    "\n",
    "def load_marker_ranges(filepath):\n",
    "    marker_ranges = {}\n",
    "    in_position_block = False\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"[genome_position]\"):\n",
    "                in_position_block = True\n",
    "                continue\n",
    "            if line.startswith(\"[\") and in_position_block:\n",
    "                # Stop if another block begins\n",
    "                break\n",
    "            if in_position_block and \"=\" in line:\n",
    "                marker, values = line.split(\"=\")\n",
    "                marker = marker.strip()\n",
    "                parts = [v.strip() for v in values.split(\",\")]\n",
    "                if len(parts) >= 3:\n",
    "                    chrom, start, end = parts[:3]\n",
    "                    marker_ranges[marker] = f\"{chrom}:{start}–{end}\"\n",
    "    return marker_ranges\n",
    "\n",
    "# Define function to process FDSTools SAST TSV files\n",
    "def process_fdstools_sast(file_path: str, min_variant_frequency_pct: float = 5.0, depth_threshold: int = 10, length_heteroplasmy_threshold: float = 90.0):\n",
    "    IUPAC_CODES = {\n",
    "        frozenset([\"A\", \"G\"]): \"R\",\n",
    "        frozenset([\"C\", \"T\"]): \"Y\",\n",
    "        frozenset([\"A\", \"C\"]): \"M\",\n",
    "        frozenset([\"G\", \"T\"]): \"K\",\n",
    "        frozenset([\"G\", \"C\"]): \"S\",\n",
    "        frozenset([\"A\", \"T\"]): \"W\"\n",
    "    }\n",
    "\n",
    "    # Load the FDSTools SAST TSV file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "    \"total_mp_max\", \"forward_pct\", \"forward\", \"forward_mp_sum\",\n",
    "    \"forward_mp_max\", \"reverse\", \"reverse_mp_sum\", \"reverse_mp_max\"]\n",
    "    \n",
    "    df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "    \n",
    "    # # Convert total_mp_sum and total to numeric types\n",
    "    df[\"total_mp_sum\"] = pd.to_numeric(df[\"total_mp_sum\"], errors=\"coerce\")\n",
    "    df[\"total\"] = pd.to_numeric(df[\"total\"], errors=\"coerce\")\n",
    "\n",
    "    # Count each marker (e.g. mtNG_001 or mtNG_007) and flag those with a single occurrence and low total\n",
    "    marker_counts = df[\"marker\"].value_counts()\n",
    "    # print(marker_counts)\n",
    "    single_low_coverage = df[df[\"marker\"].isin(marker_counts[marker_counts == 1].index) & (df[\"total\"] < depth_threshold)].copy()\n",
    "    print(single_low_coverage)\n",
    "    \n",
    "    # Step 1: Fill NaN in total and total_mp_sum with zeros\n",
    "    df[\"total\"] = df[\"total\"].fillna(0)\n",
    "    df[\"total_mp_sum\"] = df[\"total_mp_sum\"].fillna(0)\n",
    "\n",
    "    # Step 2: Flag rows with total read depth lower than threshold and low-confidence sequences\n",
    "    df[\"is_noise_or_low_frq\"] = (df[\"sequence\"].isin([\"Other sequences\"])) | (df[\"total_mp_sum\"] < min_variant_frequency_pct)\n",
    "\n",
    "    # Merge clean_marker_total_wo_OS_THR back into the main DataFrame.\n",
    "    clean_total_per_marker = df[~df[\"is_noise_or_low_frq\"]].groupby(\"marker\")[\"total\"].sum().rename(\"total_wo_noise_or_low_frq\")\n",
    "    # print(clean_total_per_marker)\n",
    "    df = df.merge(clean_total_per_marker, on=\"marker\", how=\"left\")    \n",
    "\n",
    "    # Step 3: Compute normalized variant frequency (only for retained rows)\n",
    "    df[\"variant_frequency_wo_noise_or_low_frq\"] = (df[\"total\"] / df[\"total_wo_noise_or_low_frq\"] * 100).round(2)\n",
    "\n",
    "    # Step 5: Split multiple variants\n",
    "    df = df.assign(sequence=df[\"sequence\"].str.split())\n",
    "    df = df.explode(\"sequence\").reset_index(drop=True)\n",
    "\n",
    "    # Step 4: Flag rows to drop LETS THINK ABOUT THIS, WHEN IS THE BEST TIME TO FILTER THESE OUT?\n",
    "    drop_seqs = [\"Other\", \"sequences\", \"REF\", \"N3107DEL\"]\n",
    "    df = df[(~df[\"sequence\"].isin(drop_seqs)) & (df[\"total_mp_sum\"] >= min_variant_frequency_pct)].copy()\n",
    "\n",
    "    \n",
    "    df[\"interpolated_total_coverage\"] = (np.ceil(df[\"total\"] / (df[\"total_mp_sum\"] / 100))).astype(\"Int64\")\n",
    "\n",
    "    # Step 7: Group by marker + sequence to sum within same marker\n",
    "    grouped_same_marker = df.groupby([\"marker\", \"sequence\"], as_index=False).agg(\n",
    "        total=(\"total\", \"sum\"),\n",
    "        total_mp_sum=(\"total_mp_sum\", \"sum\"),\n",
    "        interpolated_total_coverage=(\"interpolated_total_coverage\", \"max\"),\n",
    "        is_noise_or_low_frq=(\"is_noise_or_low_frq\", \"first\"),\n",
    "        total_wo_noise_or_low_frq=(\"total_wo_noise_or_low_frq\", \"first\"),\n",
    "        variant_frequency_wo_noise_or_low_frq=(\"variant_frequency_wo_noise_or_low_frq\", \"sum\")\n",
    "    )\n",
    "    \n",
    "    # # Step 9: Group across markers to merge overlapping amplicons (same variant)\n",
    "    grouped_final = grouped_same_marker.groupby(\"sequence\", as_index=False).agg(\n",
    "        marker=(\"marker\", \"first\"),\n",
    "        total=(\"total\", \"sum\"),\n",
    "        interpolated_total_coverage=(\"interpolated_total_coverage\", \"sum\"),\n",
    "        is_noise_or_low_frq=(\"is_noise_or_low_frq\", \"first\"),\n",
    "        total_wo_noise_or_low_frq=(\"total_wo_noise_or_low_frq\", \"sum\"),\n",
    "        num_markers=(\"marker\", \"nunique\")\n",
    "    )\n",
    "\n",
    "    grouped_final[\"variant_frequency\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"interpolated_total_coverage\"] * 100\n",
    "    ).round(2)\n",
    "\n",
    "    grouped_final[\"variant_frequency_wo_noise_or_low_frq\"] = (\n",
    "        grouped_final[\"total\"] / grouped_final[\"total_wo_noise_or_low_frq\"] * 100\n",
    "    ).round(2)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"sequence\"].apply(extract_position)\n",
    "    # grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    # Temporary store for merged entries\n",
    "    merged_rows = []\n",
    "    used_indices = set()\n",
    "\n",
    "    for pos, group in grouped_final.groupby(\"position\"):\n",
    "        if group.shape[0] != 2:\n",
    "            continue\n",
    "\n",
    "        # Identify deletion and substitution\n",
    "        del_row = group[group[\"sequence\"].str.endswith(\"DEL\")]\n",
    "        # print(del_row)\n",
    "        sub_row = group[~group[\"sequence\"].str.endswith(\"DEL\")]\n",
    "        # print(sub_row)\n",
    "        \n",
    "        if del_row.empty or sub_row.empty:\n",
    "            continue\n",
    "    \n",
    "        del_idx = del_row.index[0]\n",
    "        # print(del_idx)\n",
    "        sub_idx = sub_row.index[0]\n",
    "    \n",
    "        # Skip if already merged\n",
    "        if del_idx in used_indices or sub_idx in used_indices:\n",
    "            continue\n",
    "    \n",
    "        # Merge logic\n",
    "        # if del_row[\"total\"].iloc[0] >= sub_row[\"total\"].iloc[0]:\n",
    "        #     dominant_row = del_row.iloc[0]\n",
    "        # else:\n",
    "        #     dominant_row = sub_row.iloc[0]\n",
    "        total = del_row[\"total\"].iloc[0] + sub_row[\"total\"].iloc[0]\n",
    "        coverage = del_row[\"total_wo_noise_or_low_frq\"].iloc[0] \n",
    "        freq = round(total / coverage * 100, 1) if coverage else 0\n",
    "        \n",
    "        sub_seq = sub_row[\"sequence\"].iloc[0]\n",
    "        ref, pos_str, alt = re.match(r'([ACGT])(\\d+)([ACGT])', sub_seq).groups()\n",
    "    \n",
    "        # If deletion is the minor variant, return lowercase\n",
    "        del_freq = del_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "        merged_seq = f\"{ref}{pos_str}{alt.lower()}\" if del_freq < (length_heteroplasmy_threshold) else f\"{ref}{pos_str}{alt}\"\n",
    "\n",
    "        sub_freq = sub_row[\"variant_frequency\"].iloc[0]\n",
    "        sub_clean_freq = sub_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "        del_freq = del_row[\"variant_frequency\"].iloc[0]\n",
    "        del_clean_freq = del_row[\"variant_frequency_wo_noise_or_low_frq\"].iloc[0]\n",
    "    \n",
    "        freq_annotation = (\n",
    "            f\"sub:{sub_freq} ({sub_clean_freq}) | \"\n",
    "            f\"del:{del_freq} ({del_clean_freq})\"\n",
    "        )\n",
    "        merged_rows.append({\n",
    "            \"sequence\": merged_seq,\n",
    "            \"total\": total,\n",
    "            \"interpolated_total_coverage\": del_row[\"interpolated_total_coverage\"].iloc[0],\n",
    "            \"is_noise_or_low_frq\": False,\n",
    "            \"total_wo_noise_or_low_frq\": total,  # fallback\n",
    "            \"num_markers\": f\"sub:{sub_row['num_markers'].iloc[0]} | del:{del_row['num_markers'].iloc[0]}\", \n",
    "            \"variant_frequency\": freq_annotation, \n",
    "            \"variant_frequency_wo_noise_or_low_frq\": freq,\n",
    "            \"marker\": sub_row[\"marker\"].iloc[0],  # arbitrary\n",
    "            \"position\": float(pos)\n",
    "        })\n",
    "    \n",
    "        used_indices.update([del_idx, sub_idx])\n",
    "\n",
    "    # Drop merged ones and add new merged row\n",
    "    grouped_final = grouped_final.drop(index=used_indices)\n",
    "    if merged_rows:\n",
    "        grouped_final = pd.concat([grouped_final, pd.DataFrame(merged_rows)], ignore_index=True)\n",
    "\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    grouped_final[\"sequence\"] = grouped_final.apply(\n",
    "        lambda row: resolve_heteroplasmy(\n",
    "            row,\n",
    "            min_variant_frequency_pct,\n",
    "            length_heteroplasmy_threshold,\n",
    "            IUPAC_CODES\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    grouped_final = pd.concat([grouped_final, single_low_coverage], ignore_index=False)\n",
    "\n",
    "    # Load the mapping from your txt file\n",
    "    marker_to_range = load_marker_ranges(\"mtNG_lib2_v211-flank.txt\")\n",
    "    grouped_final[\"marker_range\"] = grouped_final[\"marker\"].map(marker_to_range)\n",
    "\n",
    "    grouped_final[\"position\"] = grouped_final[\"marker\"].apply(extract_position)\n",
    "    grouped_final = grouped_final.sort_values(by=\"position\").drop(columns=[\"position\"])\n",
    "\n",
    "    return grouped_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "02f41175-d116-4974-84ae-64500657e78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       marker sequence flags  total  total_mp_sum\n",
      "499  mtNG_099  No data   NaN      0           0.0\n"
     ]
    }
   ],
   "source": [
    "processed_df = process_fdstools_sast(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f5320130-1b8c-46e0-8a57-d151a566aad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>marker</th>\n",
       "      <th>total</th>\n",
       "      <th>interpolated_total_coverage</th>\n",
       "      <th>is_noise_or_low_frq</th>\n",
       "      <th>total_wo_noise_or_low_frq</th>\n",
       "      <th>num_markers</th>\n",
       "      <th>variant_frequency</th>\n",
       "      <th>variant_frequency_wo_noise_or_low_frq</th>\n",
       "      <th>flags</th>\n",
       "      <th>total_mp_sum</th>\n",
       "      <th>marker_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A263G</td>\n",
       "      <td>mtNG_002</td>\n",
       "      <td>1853</td>\n",
       "      <td>2038</td>\n",
       "      <td>False</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90.92</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:134–266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-309.1C</td>\n",
       "      <td>mtNG_003</td>\n",
       "      <td>469</td>\n",
       "      <td>588</td>\n",
       "      <td>False</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.76</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:260–368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-309.2c</td>\n",
       "      <td>mtNG_003</td>\n",
       "      <td>114</td>\n",
       "      <td>588</td>\n",
       "      <td>False</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.39</td>\n",
       "      <td>24.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:260–368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-315.1C</td>\n",
       "      <td>mtNG_003</td>\n",
       "      <td>469</td>\n",
       "      <td>588</td>\n",
       "      <td>False</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.76</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:260–368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A523-</td>\n",
       "      <td>mtNG_005</td>\n",
       "      <td>1478</td>\n",
       "      <td>1803</td>\n",
       "      <td>False</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.97</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:431–590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C524-</td>\n",
       "      <td>mtNG_005</td>\n",
       "      <td>1478</td>\n",
       "      <td>1803</td>\n",
       "      <td>False</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.97</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:431–590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A750G</td>\n",
       "      <td>mtNG_006</td>\n",
       "      <td>2298</td>\n",
       "      <td>2479</td>\n",
       "      <td>False</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>1</td>\n",
       "      <td>92.7</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:573–767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A1438G</td>\n",
       "      <td>mtNG_010</td>\n",
       "      <td>1887</td>\n",
       "      <td>2027</td>\n",
       "      <td>False</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>2</td>\n",
       "      <td>93.09</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:1278–1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>G3010A</td>\n",
       "      <td>mtNG_021</td>\n",
       "      <td>2049</td>\n",
       "      <td>2173</td>\n",
       "      <td>False</td>\n",
       "      <td>2049.0</td>\n",
       "      <td>1</td>\n",
       "      <td>94.29</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:2925–3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A3447M</td>\n",
       "      <td>mtNG_023</td>\n",
       "      <td>38</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.97</td>\n",
       "      <td>54.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:3297–3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C3462M</td>\n",
       "      <td>mtNG_023</td>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>14.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:3297–3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>T3464W</td>\n",
       "      <td>mtNG_023</td>\n",
       "      <td>11</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>15.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:3297–3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A3796G</td>\n",
       "      <td>mtNG_025</td>\n",
       "      <td>3294</td>\n",
       "      <td>3505</td>\n",
       "      <td>False</td>\n",
       "      <td>3294.0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.98</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:3620–3815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A4769G</td>\n",
       "      <td>mtNG_031</td>\n",
       "      <td>927</td>\n",
       "      <td>998</td>\n",
       "      <td>False</td>\n",
       "      <td>927.0</td>\n",
       "      <td>1</td>\n",
       "      <td>92.89</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:4720–4916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A6419M</td>\n",
       "      <td>mtNG_040</td>\n",
       "      <td>192</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.53</td>\n",
       "      <td>10.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:6292–6489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A8860G</td>\n",
       "      <td>mtNG_054</td>\n",
       "      <td>1472</td>\n",
       "      <td>1643</td>\n",
       "      <td>False</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.59</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:8680–8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A13696M</td>\n",
       "      <td>mtNG_083</td>\n",
       "      <td>220</td>\n",
       "      <td>2775</td>\n",
       "      <td>False</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.93</td>\n",
       "      <td>11.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:13645–13833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A15326G</td>\n",
       "      <td>mtNG_092</td>\n",
       "      <td>1917</td>\n",
       "      <td>2138</td>\n",
       "      <td>False</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.66</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:15256–15432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>G16129A</td>\n",
       "      <td>mtNG_097</td>\n",
       "      <td>230</td>\n",
       "      <td>291</td>\n",
       "      <td>False</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.04</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16096–16277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A16183C</td>\n",
       "      <td>mtNG_097</td>\n",
       "      <td>230</td>\n",
       "      <td>291</td>\n",
       "      <td>False</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.04</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16096–16277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>T16189c</td>\n",
       "      <td>mtNG_097</td>\n",
       "      <td>230</td>\n",
       "      <td>291</td>\n",
       "      <td>False</td>\n",
       "      <td>230.0</td>\n",
       "      <td>sub:1 | del:1</td>\n",
       "      <td>sub:68.04 (86.09) | del:11.0 (13.91)</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16096–16277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16193.1c</td>\n",
       "      <td>mtNG_097</td>\n",
       "      <td>95</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.76</td>\n",
       "      <td>41.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16096–16277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C16355T</td>\n",
       "      <td>mtNG_098</td>\n",
       "      <td>639</td>\n",
       "      <td>687</td>\n",
       "      <td>False</td>\n",
       "      <td>639.0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.01</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16216–16401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T16356C</td>\n",
       "      <td>mtNG_098</td>\n",
       "      <td>639</td>\n",
       "      <td>687</td>\n",
       "      <td>False</td>\n",
       "      <td>639.0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.01</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16216–16401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T16362C</td>\n",
       "      <td>mtNG_098</td>\n",
       "      <td>639</td>\n",
       "      <td>687</td>\n",
       "      <td>False</td>\n",
       "      <td>639.0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.01</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16216–16401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>No data</td>\n",
       "      <td>mtNG_099</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chrM:16365–16523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>T16519C</td>\n",
       "      <td>mtNG_100</td>\n",
       "      <td>1738</td>\n",
       "      <td>1824</td>\n",
       "      <td>False</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>1</td>\n",
       "      <td>95.29</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrM:16474–16569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sequence    marker  total  interpolated_total_coverage  \\\n",
       "8        A263G  mtNG_002   1853                         2038   \n",
       "1      -309.1C  mtNG_003    469                          588   \n",
       "2      -309.2c  mtNG_003    114                          588   \n",
       "3      -315.1C  mtNG_003    469                          588   \n",
       "12       A523-  mtNG_005   1478                         1803   \n",
       "18       C524-  mtNG_005   1478                         1803   \n",
       "14       A750G  mtNG_006   2298                         2479   \n",
       "5       A1438G  mtNG_010   1887                         2027   \n",
       "20      G3010A  mtNG_021   2049                         2173   \n",
       "9       A3447M  mtNG_023     38                          173   \n",
       "17      C3462M  mtNG_023     10                          173   \n",
       "24      T3464W  mtNG_023     11                          172   \n",
       "10      A3796G  mtNG_025   3294                         3505   \n",
       "11      A4769G  mtNG_031    927                          998   \n",
       "13      A6419M  mtNG_040    192                         2015   \n",
       "15      A8860G  mtNG_054   1472                         1643   \n",
       "4      A13696M  mtNG_083    220                         2775   \n",
       "6      A15326G  mtNG_092   1917                         2138   \n",
       "19     G16129A  mtNG_097    230                          291   \n",
       "7      A16183C  mtNG_097    230                          291   \n",
       "25     T16189c  mtNG_097    230                          291   \n",
       "0    -16193.1c  mtNG_097     95                          290   \n",
       "16     C16355T  mtNG_098    639                          687   \n",
       "21     T16356C  mtNG_098    639                          687   \n",
       "22     T16362C  mtNG_098    639                          687   \n",
       "499    No data  mtNG_099      0                         <NA>   \n",
       "23     T16519C  mtNG_100   1738                         1824   \n",
       "\n",
       "    is_noise_or_low_frq  total_wo_noise_or_low_frq    num_markers  \\\n",
       "8                 False                     1853.0              2   \n",
       "1                 False                      469.0              1   \n",
       "2                 False                      469.0              1   \n",
       "3                 False                      469.0              1   \n",
       "12                False                     1478.0              1   \n",
       "18                False                     1478.0              1   \n",
       "14                False                     2298.0              1   \n",
       "5                 False                     1887.0              2   \n",
       "20                False                     2049.0              1   \n",
       "9                 False                       70.0              1   \n",
       "17                False                       70.0              1   \n",
       "24                False                       70.0              1   \n",
       "10                False                     3294.0              1   \n",
       "11                False                      927.0              1   \n",
       "13                False                     1850.0              1   \n",
       "15                False                     1472.0              1   \n",
       "4                 False                     1948.0              1   \n",
       "6                 False                     1917.0              1   \n",
       "19                False                      230.0              1   \n",
       "7                 False                      230.0              1   \n",
       "25                False                      230.0  sub:1 | del:1   \n",
       "0                 False                      230.0              1   \n",
       "16                False                      639.0              1   \n",
       "21                False                      639.0              1   \n",
       "22                False                      639.0              1   \n",
       "499                 NaN                        NaN            NaN   \n",
       "23                False                     1738.0              1   \n",
       "\n",
       "                        variant_frequency  \\\n",
       "8                                   90.92   \n",
       "1                                   79.76   \n",
       "2                                   19.39   \n",
       "3                                   79.76   \n",
       "12                                  81.97   \n",
       "18                                  81.97   \n",
       "14                                   92.7   \n",
       "5                                   93.09   \n",
       "20                                  94.29   \n",
       "9                                   21.97   \n",
       "17                                   5.78   \n",
       "24                                    6.4   \n",
       "10                                  93.98   \n",
       "11                                  92.89   \n",
       "13                                   9.53   \n",
       "15                                  89.59   \n",
       "4                                    7.93   \n",
       "6                                   89.66   \n",
       "19                                  79.04   \n",
       "7                                   79.04   \n",
       "25   sub:68.04 (86.09) | del:11.0 (13.91)   \n",
       "0                                   32.76   \n",
       "16                                  93.01   \n",
       "21                                  93.01   \n",
       "22                                  93.01   \n",
       "499                                   NaN   \n",
       "23                                  95.29   \n",
       "\n",
       "     variant_frequency_wo_noise_or_low_frq flags  total_mp_sum  \\\n",
       "8                                   100.00   NaN           NaN   \n",
       "1                                   100.00   NaN           NaN   \n",
       "2                                    24.31   NaN           NaN   \n",
       "3                                   100.00   NaN           NaN   \n",
       "12                                  100.00   NaN           NaN   \n",
       "18                                  100.00   NaN           NaN   \n",
       "14                                  100.00   NaN           NaN   \n",
       "5                                   100.00   NaN           NaN   \n",
       "20                                  100.00   NaN           NaN   \n",
       "9                                    54.29   NaN           NaN   \n",
       "17                                   14.29   NaN           NaN   \n",
       "24                                   15.71   NaN           NaN   \n",
       "10                                  100.00   NaN           NaN   \n",
       "11                                  100.00   NaN           NaN   \n",
       "13                                   10.38   NaN           NaN   \n",
       "15                                  100.00   NaN           NaN   \n",
       "4                                    11.29   NaN           NaN   \n",
       "6                                   100.00   NaN           NaN   \n",
       "19                                  100.00   NaN           NaN   \n",
       "7                                   100.00   NaN           NaN   \n",
       "25                                  100.00   NaN           NaN   \n",
       "0                                    41.30   NaN           NaN   \n",
       "16                                  100.00   NaN           NaN   \n",
       "21                                  100.00   NaN           NaN   \n",
       "22                                  100.00   NaN           NaN   \n",
       "499                                    NaN   NaN           0.0   \n",
       "23                                  100.00   NaN           NaN   \n",
       "\n",
       "         marker_range  \n",
       "8        chrM:134–266  \n",
       "1        chrM:260–368  \n",
       "2        chrM:260–368  \n",
       "3        chrM:260–368  \n",
       "12       chrM:431–590  \n",
       "18       chrM:431–590  \n",
       "14       chrM:573–767  \n",
       "5      chrM:1278–1442  \n",
       "20     chrM:2925–3113  \n",
       "9      chrM:3297–3487  \n",
       "17     chrM:3297–3487  \n",
       "24     chrM:3297–3487  \n",
       "10     chrM:3620–3815  \n",
       "11     chrM:4720–4916  \n",
       "13     chrM:6292–6489  \n",
       "15     chrM:8680–8876  \n",
       "4    chrM:13645–13833  \n",
       "6    chrM:15256–15432  \n",
       "19   chrM:16096–16277  \n",
       "7    chrM:16096–16277  \n",
       "25   chrM:16096–16277  \n",
       "0    chrM:16096–16277  \n",
       "16   chrM:16216–16401  \n",
       "21   chrM:16216–16401  \n",
       "22   chrM:16216–16401  \n",
       "499  chrM:16365–16523  \n",
       "23   chrM:16474–16569  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f93534-616f-438a-94e9-13e954412c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
